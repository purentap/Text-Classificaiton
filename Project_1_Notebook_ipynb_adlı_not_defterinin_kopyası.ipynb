{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_1_Notebook_ipynb_adlı_not_defterinin_kopyası.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Run this cell to mount your drive to this notebook in order to read the datasets\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"PXQ2rNxf41HE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a377e8c-803c-4f6a-d486-483d31fc046c","executionInfo":{"status":"ok","timestamp":1652539773168,"user_tz":-180,"elapsed":110043,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9poIxsgG4uzb","executionInfo":{"status":"ok","timestamp":1652539796087,"user_tz":-180,"elapsed":728,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["## Read Dataset"],"metadata":{"id":"BWmM1YP7PD_J"}},{"cell_type":"code","source":["# Put the folder path where the datasets are located\n","PATH = \"/content/drive/MyDrive/CS445/Project 1/\""],"metadata":{"id":"cZ35nOeR43ys","executionInfo":{"status":"ok","timestamp":1652539798847,"user_tz":-180,"elapsed":6,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Read the train and test set with read_csv() method of pandas\n","train = pd.read_csv(PATH + \"train.csv\")\n","test = pd.read_csv(PATH + \"test.csv\")"],"metadata":{"id":"x8buYRli5SjM","executionInfo":{"status":"ok","timestamp":1652539801923,"user_tz":-180,"elapsed":1033,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"lZavuiD4UMQa","outputId":"6653bcbc-7555-4341-f109-837b5ff3a517"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                               text  label\n","0           0  I came here and left a review before but last ...      1\n","1           1  Had a very nice first visit here. The owner Te...      4\n","2           2  This is a gorgeous and very clean hotel.  We h...      4"],"text/html":["\n","  <div id=\"df-1c411a52-eda1-4993-806a-0989a88c2b85\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>I came here and left a review before but last ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Had a very nice first visit here. The owner Te...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>This is a gorgeous and very clean hotel.  We h...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c411a52-eda1-4993-806a-0989a88c2b85')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1c411a52-eda1-4993-806a-0989a88c2b85 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1c411a52-eda1-4993-806a-0989a88c2b85');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#check if there exists nan values\n","train.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xva3PuDmD_T","outputId":"f1d56029-1171-43b8-a3fb-7e96b7daa669"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Unnamed: 0    0\n","text          0\n","label         0\n","dtype: int64"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["train = train.drop('Unnamed: 0' , axis = 1)\n","test = test.drop('Unnamed: 0', axis = 1)"],"metadata":{"id":"uKDhfNTC_5QG","executionInfo":{"status":"ok","timestamp":1652539806215,"user_tz":-180,"elapsed":410,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Preprocess Dataset"],"metadata":{"id":"csBleyqDPJM2"}},{"cell_type":"code","source":["import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from bs4 import BeautifulSoup\n","import re\n","\n","import string"],"metadata":{"id":"hCgu4nbNubw4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"030141b2-988c-4522-cced-0b28c299e6df","executionInfo":{"status":"ok","timestamp":1652539809952,"user_tz":-180,"elapsed":2434,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["# Define a function to perform preprocessing. This function can perform things like lowercasing, stemming, removing stopwords, etc.\n"," \n","stop_words = set(stopwords.words('english'))\n","def preprocess(text: str):\n","  #lowercasing\n","  text = text.lower()\n","  #remove html tags\n","  text = BeautifulSoup(text).get_text()\n","  #remove URLs\n","  text = re.sub(r'http\\S+' , '', text)\n","  #punctuation removal\n","  text = text.translate(text.maketrans('', '', string.punctuation))\n","  #remove extra white spaces\n","  text = re.sub(' +', ' ', text)\n","  #tokenization\n","  word_tokens = word_tokenize(text)\n","  #stop word removal\n","  text = ' '.join([w for w in word_tokens if w not in stop_words])\n","  \n","  return text"],"metadata":{"id":"OSiAj6atwZzi","executionInfo":{"status":"ok","timestamp":1652539813211,"user_tz":-180,"elapsed":299,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Apply your preprocessing function to your text fields.\n","\n","train.text = train.text.apply(preprocess)\n","test.text = test.text.apply(preprocess)\n","\n","train.shape, test.shape"],"metadata":{"id":"saAhAw_vyu9T","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0df156b-deca-472a-c261-3a4b14478bbd","executionInfo":{"status":"ok","timestamp":1652539832660,"user_tz":-180,"elapsed":16309,"user":{"displayName":"Püren Tap (Student)","userId":"11403674556009753814"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((18000, 2), (2000, 2))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Create your binary and multiclass datasets\n","binary_train = train.sample(frac=0.5, random_state = 200)\n","multiclass_train = train.drop(binary_train.index)\n","\n","binary_test = test.sample(frac=0.5, random_state=200)\n","multiclass_test = test.drop(binary_test.index)\n","\n","\n","\n","# For binary dataset, get rid of the class 3 in the dataset and map class 1 and 2 to 0, and class 4 and 5 to 1\n","#drop the rows which has label == 3\n","binary_train = binary_train.drop(binary_train[binary_train.label == 3].index)\n","binary_train.loc[binary_train[\"label\"] == 1, \"label\"] = 0\n","binary_train.loc[binary_train[\"label\"] == 2, \"label\"] = 0\n","binary_train.loc[binary_train[\"label\"] == 4, \"label\"] = 1\n","binary_train.loc[binary_train[\"label\"] == 5, \"label\"] = 1\n","\n","\n","#do the train and test handling for binary_test\n","#drop the rows which has label == 3\n","binary_test = binary_test.drop(binary_test[binary_test.label == 3].index)\n","\n","binary_test.loc[binary_test[\"label\"] == 1, \"label\"] = 0\n","binary_test.loc[binary_test[\"label\"] == 2, \"label\"] = 0\n","binary_test.loc[binary_test[\"label\"] == 4, \"label\"] = 1\n","binary_test.loc[binary_test[\"label\"] == 5, \"label\"] = 1\n","\n","binary_train_x = binary_train['text']\n","binary_train_y = binary_train['label']\n","\n","binary_test_x = binary_test['text']\n","binary_test_y = binary_test['label']\n","\n","# For multiclass dataset, make sure your classes starts from 0 and goes until 4. (5->4, 4->3, 3->2, 2->1, 1->0)\n","for i in range(1,6):\n","  multiclass_train.loc[multiclass_train[\"label\"] == i, \"label\"] = i-1\n","  multiclass_test.loc[multiclass_test[\"label\"] == i, \"label\"] = i-1\n","\n","multiclass_train_x = multiclass_train[\"text\"]\n","multiclass_train_y = multiclass_train[\"label\"]\n","\n","multiclass_test_x = multiclass_test[\"text\"]\n","multiclass_test_y = multiclass_test[\"label\"]"],"metadata":{"id":"MJWiNm2ZrO8m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"fbz48mNfttuo"}},{"cell_type":"markdown","source":["## Non-Neural Models"],"metadata":{"id":"y65GxGIFAC_K"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score,confusion_matrix,accuracy_score"],"metadata":{"id":"BYhkcMWouazd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Naive Bayes"],"metadata":{"id":"4MZIaJFXWScs"}},{"cell_type":"code","source":["# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n","\n","# Create a class for converting sparse matrix output of TfidfVectorizer to dense matrix for feeding into GaussianNB\n","class DenseTransformer(TransformerMixin):\n","\n","    def fit(self, X, y=None, **fit_params):\n","        return self\n","\n","    def transform(self, X, y=None, **fit_params):\n","        return X.todense()\n","\n","\n","# Initiate the pipeline with required components.You can use Pipeline class of sklearn -> https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n","# There will be three components; 1) TfidfVectorizer 2) DenseTransformer 3) Naive Bayes classifier.\n","\n","naiveBayes_components = [('TfidfVectorizer' , TfidfVectorizer(analyzer = 'word')), ('DenseTransformer' , DenseTransformer()), ('NBClassifier' , GaussianNB())]\n","naiveBayes_pipeline = Pipeline(naiveBayes_components)\n","\n","#tfidfvectorizer = TfidfVectorizer()\n","#tfidf_wm = tfidfvectorizer.fit_transform(binary_train['text'])\n","#tfidf_wm = tfidfvectorizer.fit_transform(' '.join(map(str,binary_train['text'])))\n","\n","\n","\n","# Set the hyperparameter space that will be scanned with GridSearchCV.\n","grid_parameters =  {\n","    'TfidfVectorizer__ngram_range' : [(1,1) , (1,2), (1,3) ],\n","    'TfidfVectorizer__min_df' : [100, 500, 1000]\n","\n","}\n","\n"],"metadata":{"id":"Tr32alf3WXmM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Binary"],"metadata":{"id":"0PjodOpko5pJ"}},{"cell_type":"code","source":["%%time\n","# Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.\n","\n","clf = GridSearchCV(naiveBayes_pipeline, grid_parameters,verbose=10, scoring='f1_macro')\n","clf.fit(binary_train_x, binary_train_y)\n"],"metadata":{"id":"vlZRfzqPo9iv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"231cb02a-c2c5-4e4b-9603-c323ed396f2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 9 candidates, totalling 45 fits\n","[CV 1/5; 1/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 1/5; 1/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1);, score=0.858 total time=   0.4s\n","[CV 2/5; 1/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 2/5; 1/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1);, score=0.848 total time=   0.4s\n","[CV 3/5; 1/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 3/5; 1/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1);, score=0.836 total time=   0.4s\n","[CV 4/5; 1/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 4/5; 1/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1);, score=0.845 total time=   0.4s\n","[CV 5/5; 1/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 5/5; 1/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 1);, score=0.850 total time=   0.4s\n","[CV 1/5; 2/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 1/5; 2/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2);, score=0.870 total time=   1.1s\n","[CV 2/5; 2/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 2/5; 2/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2);, score=0.853 total time=   1.1s\n","[CV 3/5; 2/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 3/5; 2/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2);, score=0.846 total time=   1.0s\n","[CV 4/5; 2/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 4/5; 2/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2);, score=0.851 total time=   1.1s\n","[CV 5/5; 2/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 5/5; 2/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 2);, score=0.857 total time=   1.1s\n","[CV 1/5; 3/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 1/5; 3/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3);, score=0.870 total time=   1.9s\n","[CV 2/5; 3/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 2/5; 3/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3);, score=0.853 total time=   1.8s\n","[CV 3/5; 3/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 3/5; 3/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3);, score=0.846 total time=   1.8s\n","[CV 4/5; 3/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 4/5; 3/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3);, score=0.851 total time=   1.8s\n","[CV 5/5; 3/9] START TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 5/5; 3/9] END TfidfVectorizer__min_df=100, TfidfVectorizer__ngram_range=(1, 3);, score=0.857 total time=   1.8s\n","[CV 1/5; 4/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 1/5; 4/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1);, score=0.761 total time=   0.3s\n","[CV 2/5; 4/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 2/5; 4/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1);, score=0.756 total time=   0.4s\n","[CV 3/5; 4/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 3/5; 4/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1);, score=0.727 total time=   0.4s\n","[CV 4/5; 4/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 4/5; 4/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1);, score=0.767 total time=   0.3s\n","[CV 5/5; 4/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 5/5; 4/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 1);, score=0.764 total time=   0.4s\n","[CV 1/5; 5/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 1/5; 5/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2);, score=0.761 total time=   1.0s\n","[CV 2/5; 5/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 2/5; 5/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2);, score=0.756 total time=   1.0s\n","[CV 3/5; 5/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 3/5; 5/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2);, score=0.727 total time=   1.0s\n","[CV 4/5; 5/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 4/5; 5/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2);, score=0.767 total time=   1.0s\n","[CV 5/5; 5/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 5/5; 5/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 2);, score=0.764 total time=   1.0s\n","[CV 1/5; 6/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 1/5; 6/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3);, score=0.761 total time=   1.7s\n","[CV 2/5; 6/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 2/5; 6/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3);, score=0.756 total time=   1.7s\n","[CV 3/5; 6/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 3/5; 6/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3);, score=0.727 total time=   1.7s\n","[CV 4/5; 6/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 4/5; 6/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3);, score=0.767 total time=   1.7s\n","[CV 5/5; 6/9] START TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 5/5; 6/9] END TfidfVectorizer__min_df=500, TfidfVectorizer__ngram_range=(1, 3);, score=0.764 total time=   1.7s\n","[CV 1/5; 7/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 1/5; 7/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1);, score=0.657 total time=   0.3s\n","[CV 2/5; 7/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 2/5; 7/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1);, score=0.631 total time=   0.4s\n","[CV 3/5; 7/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 3/5; 7/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1);, score=0.650 total time=   0.3s\n","[CV 4/5; 7/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 4/5; 7/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1);, score=0.657 total time=   0.3s\n","[CV 5/5; 7/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1)\n","[CV 5/5; 7/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 1);, score=0.656 total time=   0.3s\n","[CV 1/5; 8/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 1/5; 8/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2);, score=0.657 total time=   1.0s\n","[CV 2/5; 8/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 2/5; 8/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2);, score=0.631 total time=   1.0s\n","[CV 3/5; 8/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 3/5; 8/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2);, score=0.650 total time=   1.0s\n","[CV 4/5; 8/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 4/5; 8/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2);, score=0.657 total time=   1.0s\n","[CV 5/5; 8/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2)\n","[CV 5/5; 8/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 2);, score=0.656 total time=   1.0s\n","[CV 1/5; 9/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 1/5; 9/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3);, score=0.657 total time=   1.7s\n","[CV 2/5; 9/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 2/5; 9/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3);, score=0.631 total time=   1.7s\n","[CV 3/5; 9/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 3/5; 9/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3);, score=0.650 total time=   1.8s\n","[CV 4/5; 9/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 4/5; 9/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3);, score=0.657 total time=   1.7s\n","[CV 5/5; 9/9] START TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3)\n","[CV 5/5; 9/9] END TfidfVectorizer__min_df=1000, TfidfVectorizer__ngram_range=(1, 3);, score=0.656 total time=   1.8s\n","CPU times: user 48.5 s, sys: 931 ms, total: 49.4 s\n","Wall time: 49.5 s\n"]}]},{"cell_type":"code","source":["# Report the standart deviation of split scores for each hyperparameter group.\n","\n","grid_scores = pd.DataFrame(clf.cv_results_)\n","grid_scores\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":552},"id":"FTkjq_qmSwWo","outputId":"6cff5348-46d0-46d7-aea5-34e6c3de41f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0       0.355416      0.010732         0.073161        0.002172   \n","1       0.930103      0.026313         0.139128        0.004090   \n","2       1.612090      0.022647         0.209239        0.009408   \n","3       0.288320      0.005828         0.059916        0.002671   \n","4       0.849975      0.010329         0.123081        0.004142   \n","5       1.523374      0.018605         0.189074        0.006977   \n","6       0.283407      0.008797         0.062042        0.003985   \n","7       0.848729      0.012967         0.122098        0.006940   \n","8       1.557600      0.010151         0.185895        0.009170   \n","\n","  param_TfidfVectorizer__min_df param_TfidfVectorizer__ngram_range  \\\n","0                           100                             (1, 1)   \n","1                           100                             (1, 2)   \n","2                           100                             (1, 3)   \n","3                           500                             (1, 1)   \n","4                           500                             (1, 2)   \n","5                           500                             (1, 3)   \n","6                          1000                             (1, 1)   \n","7                          1000                             (1, 2)   \n","8                          1000                             (1, 3)   \n","\n","                                              params  split0_test_score  \\\n","0  {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.858337   \n","1  {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.870184   \n","2  {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.870184   \n","3  {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.760586   \n","4  {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.760586   \n","5  {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.760586   \n","6  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.656972   \n","7  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.656972   \n","8  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.656972   \n","\n","   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n","0           0.847872           0.835887           0.844971           0.849749   \n","1           0.852749           0.845631           0.851257           0.857407   \n","2           0.852749           0.845631           0.851257           0.857407   \n","3           0.756348           0.726897           0.766743           0.763849   \n","4           0.756348           0.726897           0.766743           0.763849   \n","5           0.756348           0.726897           0.766743           0.763849   \n","6           0.630911           0.649506           0.657044           0.655967   \n","7           0.630911           0.649506           0.657044           0.655967   \n","8           0.630911           0.649506           0.657044           0.655967   \n","\n","   mean_test_score  std_test_score  rank_test_score  \n","0         0.847363        0.007263                3  \n","1         0.855446        0.008273                1  \n","2         0.855446        0.008273                1  \n","3         0.754884        0.014415                4  \n","4         0.754884        0.014415                4  \n","5         0.754884        0.014415                4  \n","6         0.650080        0.009985                7  \n","7         0.650080        0.009985                7  \n","8         0.650080        0.009985                7  "],"text/html":["\n","  <div id=\"df-18b8231a-d3c0-435c-afc4-e403ed8d7e32\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_TfidfVectorizer__min_df</th>\n","      <th>param_TfidfVectorizer__ngram_range</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.355416</td>\n","      <td>0.010732</td>\n","      <td>0.073161</td>\n","      <td>0.002172</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.858337</td>\n","      <td>0.847872</td>\n","      <td>0.835887</td>\n","      <td>0.844971</td>\n","      <td>0.849749</td>\n","      <td>0.847363</td>\n","      <td>0.007263</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.930103</td>\n","      <td>0.026313</td>\n","      <td>0.139128</td>\n","      <td>0.004090</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.870184</td>\n","      <td>0.852749</td>\n","      <td>0.845631</td>\n","      <td>0.851257</td>\n","      <td>0.857407</td>\n","      <td>0.855446</td>\n","      <td>0.008273</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.612090</td>\n","      <td>0.022647</td>\n","      <td>0.209239</td>\n","      <td>0.009408</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.870184</td>\n","      <td>0.852749</td>\n","      <td>0.845631</td>\n","      <td>0.851257</td>\n","      <td>0.857407</td>\n","      <td>0.855446</td>\n","      <td>0.008273</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.288320</td>\n","      <td>0.005828</td>\n","      <td>0.059916</td>\n","      <td>0.002671</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.760586</td>\n","      <td>0.756348</td>\n","      <td>0.726897</td>\n","      <td>0.766743</td>\n","      <td>0.763849</td>\n","      <td>0.754884</td>\n","      <td>0.014415</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.849975</td>\n","      <td>0.010329</td>\n","      <td>0.123081</td>\n","      <td>0.004142</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.760586</td>\n","      <td>0.756348</td>\n","      <td>0.726897</td>\n","      <td>0.766743</td>\n","      <td>0.763849</td>\n","      <td>0.754884</td>\n","      <td>0.014415</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.523374</td>\n","      <td>0.018605</td>\n","      <td>0.189074</td>\n","      <td>0.006977</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.760586</td>\n","      <td>0.756348</td>\n","      <td>0.726897</td>\n","      <td>0.766743</td>\n","      <td>0.763849</td>\n","      <td>0.754884</td>\n","      <td>0.014415</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.283407</td>\n","      <td>0.008797</td>\n","      <td>0.062042</td>\n","      <td>0.003985</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.656972</td>\n","      <td>0.630911</td>\n","      <td>0.649506</td>\n","      <td>0.657044</td>\n","      <td>0.655967</td>\n","      <td>0.650080</td>\n","      <td>0.009985</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.848729</td>\n","      <td>0.012967</td>\n","      <td>0.122098</td>\n","      <td>0.006940</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.656972</td>\n","      <td>0.630911</td>\n","      <td>0.649506</td>\n","      <td>0.657044</td>\n","      <td>0.655967</td>\n","      <td>0.650080</td>\n","      <td>0.009985</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.557600</td>\n","      <td>0.010151</td>\n","      <td>0.185895</td>\n","      <td>0.009170</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.656972</td>\n","      <td>0.630911</td>\n","      <td>0.649506</td>\n","      <td>0.657044</td>\n","      <td>0.655967</td>\n","      <td>0.650080</td>\n","      <td>0.009985</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b8231a-d3c0-435c-afc4-e403ed8d7e32')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18b8231a-d3c0-435c-afc4-e403ed8d7e32 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18b8231a-d3c0-435c-afc4-e403ed8d7e32');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["# Show the best parameter set for given dataset and hyperparameter space.\n","\n","print(\"Best Score: \", clf.best_score_)\n","print(\"Best Hyperparameters: \", clf.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOzCsFzkS2ZY","outputId":"475c8121-f84f-43b6-f433-923bb0d84858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score:  0.8554456286765809\n","Best Hyperparameters:  {'TfidfVectorizer__min_df': 100, 'TfidfVectorizer__ngram_range': (1, 2)}\n"]}]},{"cell_type":"code","source":["# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #\n","# Create your Pipeline object with the best parameter set.\n","\n","naiveBayes_components = [('TfidfVectorizer' , TfidfVectorizer(analyzer = 'word', ngram_range = (1,2), min_df = 100)), ('DenseTransformer' , DenseTransformer()), ('NBClassifier' , GaussianNB())]\n","naiveBayes_pipeline = Pipeline(naiveBayes_components)\n","\n","\n","\n","# Fit your pipeline on training set.\n","\n","naiveBayes_pipeline.fit(binary_train_x, binary_train_y)\n","\n","# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.\n","pred_y= naiveBayes_pipeline.predict(binary_test_x,)\n","\n","f1_score = f1_score(binary_test_y,pred_y)\n","acc_score = accuracy_score(binary_test_y, pred_y)\n","print(\"F1 Score: \", f1_score)\n","print(\"Accuracy Score: \", acc_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brKBgMovQDct","outputId":"95c533ae-7c6f-4c52-d8b3-f040974dc941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score:  0.853960396039604\n","Accuracy Score:  0.854679802955665\n"]}]},{"cell_type":"code","source":["#Confusion Matrix\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cf_matrix = confusion_matrix(binary_test_y, pred_y)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n","                              display_labels= naiveBayes_pipeline.classes_)\n","disp.plot()\n","\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"ery_ei8zU5Z4","outputId":"1c540aec-0e60-4ed0-c850-c5968a8d42a0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["#### Multi"],"metadata":{"id":"gUmILCQmpPAE"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score,confusion_matrix,accuracy_score"],"metadata":{"id":"E8lnb5b08Ruk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for multiclass classification.\n","\n","grid_parameters =  {\n","    'TfidfVectorizer__ngram_range' : [(1,1) , (1,2), (1,3)],\n","    'TfidfVectorizer__min_df' : [100, 500, 1000],\n","    'TfidfVectorizer__norm' : ['l1' , 'l2']\n","\n","}\n","\n","clf = GridSearchCV(naiveBayes_pipeline, grid_parameters,verbose=1, scoring='f1_macro')\n","clf.fit(multiclass_train_x, multiclass_train_y)\n","\n"],"metadata":{"id":"Od0ZnT7MpSdC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca53a8dd-73b6-4a67-97a1-380ea3625454"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 18 candidates, totalling 90 fits\n","CPU times: user 2min 7s, sys: 2.82 s, total: 2min 10s\n","Wall time: 2min 11s\n"]}]},{"cell_type":"code","source":["# Report the standart deviation of split scores for each hyperparameter group.\n","\n","grid_scores = pd.DataFrame(clf.cv_results_)\n","grid_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":990},"id":"ppiTUXUhyrjl","outputId":"f9061264-a04e-4c11-8d76-d7d5d0657385"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0        0.458296      0.011358         0.134720        0.005017   \n","1        0.447850      0.006711         0.132899        0.005058   \n","2        1.206519      0.018048         0.216033        0.006655   \n","3        1.201664      0.014003         0.220490        0.008172   \n","4        2.159760      0.024710         0.298527        0.007269   \n","5        2.130520      0.029523         0.302568        0.013400   \n","6        0.363366      0.007699         0.083047        0.004635   \n","7        0.365935      0.009824         0.080544        0.001591   \n","8        1.099606      0.005497         0.162758        0.006590   \n","9        1.108991      0.021625         0.161504        0.002469   \n","10       2.037882      0.013212         0.244587        0.004661   \n","11       2.445655      0.786956         0.247730        0.008527   \n","12       0.361098      0.009545         0.076860        0.003855   \n","13       0.361996      0.009645         0.077767        0.004382   \n","14       1.120813      0.025653         0.160426        0.007224   \n","15       1.094474      0.009569         0.158472        0.008842   \n","16       2.014940      0.020805         0.241746        0.005148   \n","17       2.032446      0.017512         0.243481        0.006609   \n","\n","   param_TfidfVectorizer__min_df param_TfidfVectorizer__ngram_range  \\\n","0                            100                             (1, 1)   \n","1                            100                             (1, 1)   \n","2                            100                             (1, 2)   \n","3                            100                             (1, 2)   \n","4                            100                             (1, 3)   \n","5                            100                             (1, 3)   \n","6                            500                             (1, 1)   \n","7                            500                             (1, 1)   \n","8                            500                             (1, 2)   \n","9                            500                             (1, 2)   \n","10                           500                             (1, 3)   \n","11                           500                             (1, 3)   \n","12                          1000                             (1, 1)   \n","13                          1000                             (1, 1)   \n","14                          1000                             (1, 2)   \n","15                          1000                             (1, 2)   \n","16                          1000                             (1, 3)   \n","17                          1000                             (1, 3)   \n","\n","   param_TfidfVectorizer__norm  \\\n","0                           l1   \n","1                           l2   \n","2                           l1   \n","3                           l2   \n","4                           l1   \n","5                           l2   \n","6                           l1   \n","7                           l2   \n","8                           l1   \n","9                           l2   \n","10                          l1   \n","11                          l2   \n","12                          l1   \n","13                          l2   \n","14                          l1   \n","15                          l2   \n","16                          l1   \n","17                          l2   \n","\n","                                               params  split0_test_score  \\\n","0   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.417301   \n","1   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.436418   \n","2   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.419563   \n","3   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.444514   \n","4   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.419563   \n","5   {'TfidfVectorizer__min_df': 100, 'TfidfVectori...           0.444514   \n","6   {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.377962   \n","7   {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.387935   \n","8   {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.377962   \n","9   {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.387935   \n","10  {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.377962   \n","11  {'TfidfVectorizer__min_df': 500, 'TfidfVectori...           0.387935   \n","12  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.322803   \n","13  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.325018   \n","14  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.322803   \n","15  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.325018   \n","16  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.322803   \n","17  {'TfidfVectorizer__min_df': 1000, 'TfidfVector...           0.325018   \n","\n","    split1_test_score  split2_test_score  split3_test_score  \\\n","0            0.431554           0.429753           0.435580   \n","1            0.452912           0.456288           0.460838   \n","2            0.444462           0.444753           0.442315   \n","3            0.462457           0.473281           0.464048   \n","4            0.444462           0.444753           0.442315   \n","5            0.462457           0.473281           0.464048   \n","6            0.391137           0.389008           0.374723   \n","7            0.417106           0.422662           0.393659   \n","8            0.391137           0.389008           0.374723   \n","9            0.417106           0.422662           0.393659   \n","10           0.391137           0.389008           0.374723   \n","11           0.417106           0.422662           0.393659   \n","12           0.290914           0.312626           0.306795   \n","13           0.306731           0.312380           0.307671   \n","14           0.290914           0.312626           0.306795   \n","15           0.306731           0.312380           0.307671   \n","16           0.290914           0.312626           0.306795   \n","17           0.306731           0.312380           0.307671   \n","\n","    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n","0            0.420396         0.426917        0.006922                6  \n","1            0.434259         0.448143        0.010775                3  \n","2            0.424894         0.435197        0.010756                4  \n","3            0.446227         0.458105        0.011048                1  \n","4            0.424894         0.435197        0.010756                4  \n","5            0.446227         0.458105        0.011048                1  \n","6            0.365068         0.379580        0.009584               10  \n","7            0.374267         0.399126        0.018167                7  \n","8            0.365068         0.379580        0.009584               10  \n","9            0.374267         0.399126        0.018167                7  \n","10           0.365068         0.379580        0.009584               10  \n","11           0.374267         0.399126        0.018167                7  \n","12           0.301843         0.306996        0.010647               16  \n","13           0.302987         0.310957        0.007641               13  \n","14           0.301843         0.306996        0.010647               16  \n","15           0.302987         0.310957        0.007641               13  \n","16           0.301843         0.306996        0.010647               16  \n","17           0.302987         0.310957        0.007641               13  "],"text/html":["\n","  <div id=\"df-fe6ff0e0-9ed8-402a-9ff3-95b68a61b3d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_TfidfVectorizer__min_df</th>\n","      <th>param_TfidfVectorizer__ngram_range</th>\n","      <th>param_TfidfVectorizer__norm</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.458296</td>\n","      <td>0.011358</td>\n","      <td>0.134720</td>\n","      <td>0.005017</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.417301</td>\n","      <td>0.431554</td>\n","      <td>0.429753</td>\n","      <td>0.435580</td>\n","      <td>0.420396</td>\n","      <td>0.426917</td>\n","      <td>0.006922</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.447850</td>\n","      <td>0.006711</td>\n","      <td>0.132899</td>\n","      <td>0.005058</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.436418</td>\n","      <td>0.452912</td>\n","      <td>0.456288</td>\n","      <td>0.460838</td>\n","      <td>0.434259</td>\n","      <td>0.448143</td>\n","      <td>0.010775</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.206519</td>\n","      <td>0.018048</td>\n","      <td>0.216033</td>\n","      <td>0.006655</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.419563</td>\n","      <td>0.444462</td>\n","      <td>0.444753</td>\n","      <td>0.442315</td>\n","      <td>0.424894</td>\n","      <td>0.435197</td>\n","      <td>0.010756</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.201664</td>\n","      <td>0.014003</td>\n","      <td>0.220490</td>\n","      <td>0.008172</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.444514</td>\n","      <td>0.462457</td>\n","      <td>0.473281</td>\n","      <td>0.464048</td>\n","      <td>0.446227</td>\n","      <td>0.458105</td>\n","      <td>0.011048</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.159760</td>\n","      <td>0.024710</td>\n","      <td>0.298527</td>\n","      <td>0.007269</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.419563</td>\n","      <td>0.444462</td>\n","      <td>0.444753</td>\n","      <td>0.442315</td>\n","      <td>0.424894</td>\n","      <td>0.435197</td>\n","      <td>0.010756</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.130520</td>\n","      <td>0.029523</td>\n","      <td>0.302568</td>\n","      <td>0.013400</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 100, 'TfidfVectori...</td>\n","      <td>0.444514</td>\n","      <td>0.462457</td>\n","      <td>0.473281</td>\n","      <td>0.464048</td>\n","      <td>0.446227</td>\n","      <td>0.458105</td>\n","      <td>0.011048</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.363366</td>\n","      <td>0.007699</td>\n","      <td>0.083047</td>\n","      <td>0.004635</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.377962</td>\n","      <td>0.391137</td>\n","      <td>0.389008</td>\n","      <td>0.374723</td>\n","      <td>0.365068</td>\n","      <td>0.379580</td>\n","      <td>0.009584</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.365935</td>\n","      <td>0.009824</td>\n","      <td>0.080544</td>\n","      <td>0.001591</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.387935</td>\n","      <td>0.417106</td>\n","      <td>0.422662</td>\n","      <td>0.393659</td>\n","      <td>0.374267</td>\n","      <td>0.399126</td>\n","      <td>0.018167</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.099606</td>\n","      <td>0.005497</td>\n","      <td>0.162758</td>\n","      <td>0.006590</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.377962</td>\n","      <td>0.391137</td>\n","      <td>0.389008</td>\n","      <td>0.374723</td>\n","      <td>0.365068</td>\n","      <td>0.379580</td>\n","      <td>0.009584</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.108991</td>\n","      <td>0.021625</td>\n","      <td>0.161504</td>\n","      <td>0.002469</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.387935</td>\n","      <td>0.417106</td>\n","      <td>0.422662</td>\n","      <td>0.393659</td>\n","      <td>0.374267</td>\n","      <td>0.399126</td>\n","      <td>0.018167</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2.037882</td>\n","      <td>0.013212</td>\n","      <td>0.244587</td>\n","      <td>0.004661</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.377962</td>\n","      <td>0.391137</td>\n","      <td>0.389008</td>\n","      <td>0.374723</td>\n","      <td>0.365068</td>\n","      <td>0.379580</td>\n","      <td>0.009584</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2.445655</td>\n","      <td>0.786956</td>\n","      <td>0.247730</td>\n","      <td>0.008527</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 500, 'TfidfVectori...</td>\n","      <td>0.387935</td>\n","      <td>0.417106</td>\n","      <td>0.422662</td>\n","      <td>0.393659</td>\n","      <td>0.374267</td>\n","      <td>0.399126</td>\n","      <td>0.018167</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.361098</td>\n","      <td>0.009545</td>\n","      <td>0.076860</td>\n","      <td>0.003855</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.322803</td>\n","      <td>0.290914</td>\n","      <td>0.312626</td>\n","      <td>0.306795</td>\n","      <td>0.301843</td>\n","      <td>0.306996</td>\n","      <td>0.010647</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.361996</td>\n","      <td>0.009645</td>\n","      <td>0.077767</td>\n","      <td>0.004382</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.325018</td>\n","      <td>0.306731</td>\n","      <td>0.312380</td>\n","      <td>0.307671</td>\n","      <td>0.302987</td>\n","      <td>0.310957</td>\n","      <td>0.007641</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1.120813</td>\n","      <td>0.025653</td>\n","      <td>0.160426</td>\n","      <td>0.007224</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.322803</td>\n","      <td>0.290914</td>\n","      <td>0.312626</td>\n","      <td>0.306795</td>\n","      <td>0.301843</td>\n","      <td>0.306996</td>\n","      <td>0.010647</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1.094474</td>\n","      <td>0.009569</td>\n","      <td>0.158472</td>\n","      <td>0.008842</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.325018</td>\n","      <td>0.306731</td>\n","      <td>0.312380</td>\n","      <td>0.307671</td>\n","      <td>0.302987</td>\n","      <td>0.310957</td>\n","      <td>0.007641</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2.014940</td>\n","      <td>0.020805</td>\n","      <td>0.241746</td>\n","      <td>0.005148</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>l1</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.322803</td>\n","      <td>0.290914</td>\n","      <td>0.312626</td>\n","      <td>0.306795</td>\n","      <td>0.301843</td>\n","      <td>0.306996</td>\n","      <td>0.010647</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2.032446</td>\n","      <td>0.017512</td>\n","      <td>0.243481</td>\n","      <td>0.006609</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>l2</td>\n","      <td>{'TfidfVectorizer__min_df': 1000, 'TfidfVector...</td>\n","      <td>0.325018</td>\n","      <td>0.306731</td>\n","      <td>0.312380</td>\n","      <td>0.307671</td>\n","      <td>0.302987</td>\n","      <td>0.310957</td>\n","      <td>0.007641</td>\n","      <td>13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe6ff0e0-9ed8-402a-9ff3-95b68a61b3d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fe6ff0e0-9ed8-402a-9ff3-95b68a61b3d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fe6ff0e0-9ed8-402a-9ff3-95b68a61b3d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# Show the best parameter set for given dataset and hyperparameter space.\n","\n","print(\"Best Score: \", clf.best_score_)\n","print(\"Best Hyperparameters: \", clf.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_MPwSvpyuIc","outputId":"7d65cc17-3e7f-4790-a30b-2b1725499dd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score:  0.45810533402035347\n","Best Hyperparameters:  {'TfidfVectorizer__min_df': 100, 'TfidfVectorizer__ngram_range': (1, 2), 'TfidfVectorizer__norm': 'l2'}\n"]}]},{"cell_type":"code","source":["# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #\n","# Create your pipeline object with the best parameter set.\n","\n","naiveBayes_components = [('TfidfVectorizer' , TfidfVectorizer(analyzer = 'word', ngram_range = (1,2), min_df = 100)), ('DenseTransformer' , DenseTransformer()), ('NBClassifier' , GaussianNB())]\n","naiveBayes_pipeline = Pipeline(naiveBayes_components)\n","\n","\n","# Fit your pipeline on training set.\n","naiveBayes_pipeline.fit(multiclass_train_x, multiclass_train_y)\n","\n","# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.\n","multiclass_pred_y= naiveBayes_pipeline.predict(multiclass_test_x)\n","\n","f1_score = f1_score(multiclass_test_y,multiclass_pred_y, average =\"macro\")\n","acc_score = accuracy_score(multiclass_test_y, multiclass_pred_y)\n","print(\"F1 Score: \", f1_score)\n","print(\"Accuracy Score: \", acc_score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngBOoeAl21ue","outputId":"e7253a1f-54f9-42b0-e152-adf71e778c21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score:  0.46108191335759807\n","Accuracy Score:  0.475\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cf_matrix = confusion_matrix(multiclass_test_y, multiclass_pred_y)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n","                              display_labels= naiveBayes_pipeline.classes_)\n","disp.plot()\n","\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"SFkp4T1aAnB7","outputId":"ce50c37b-e333-47c2-d287-de860039122e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"EMNf8zC50lQQ"}},{"cell_type":"code","source":["# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","\n","# Initiate the pipeline with required components.You can use Pipeline class of sklearn -> https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n","# There will be three components; 1) Word weightning 2) Logistic Regression classifier.\n","\n","logistic_regression_components = [('WordWeightning' ,TfidfVectorizer(analyzer = 'word')), ('LogRegClassifier', LogisticRegression(random_state = 22))]\n","logistic_regression_pipeline = Pipeline(logistic_regression_components)\n","\n","\n","\n","#Set the hyperparameter space that will be scanned.\n","logreg_grid_parameters =  {\n","    'WordWeightning__ngram_range' : [(1,1) , (1,2), (1,3)],\n","    'WordWeightning__min_df' : [100, 500, 1000],\n","    'LogRegClassifier__penalty' : ['l1' , 'l2'],\n","    'LogRegClassifier__l1_ratio' : [0.0, 0.5, 1.0]\n","\n","}\n","\n"],"metadata":{"id":"M5ySIl3e552q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Binary"],"metadata":{"id":"zTmaa_tHTWZ0"}},{"cell_type":"code","source":["%%time\n","# Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.\n","\n","clf = GridSearchCV(logistic_regression_pipeline, logreg_grid_parameters,verbose = 4, scoring='f1_macro')\n","clf.fit(binary_train_x, binary_train_y)\n","\n"],"metadata":{"id":"atCcPl1NTQWr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f558a5b-fe11-433c-f11f-e29f8433cb7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 54 candidates, totalling 270 fits\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   2.6s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.7s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.7s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.889 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.881 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.887 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.876 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.883 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.1s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.883 total time=   1.1s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.879 total time=   1.1s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.885 total time=   1.1s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.883 total time=   1.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.879 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.885 total time=   1.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.781 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.764 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.770 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.780 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.783 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.781 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.764 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.770 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.780 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.783 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.781 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.764 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.770 total time=   1.7s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.780 total time=   1.7s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.783 total time=   1.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.652 total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.635 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.663 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.652 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.635 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.663 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.652 total time=   1.7s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.635 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   2.6s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.663 total time=   1.7s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.889 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.881 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.887 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.876 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.883 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.883 total time=   1.1s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.1s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.879 total time=   1.1s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.885 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.883 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.879 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.885 total time=   1.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.781 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.764 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.770 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.780 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.783 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.781 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.764 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.770 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.780 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.783 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.781 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.764 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.770 total time=   1.7s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.780 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.783 total time=   1.7s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.652 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.635 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.663 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.652 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.635 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.663 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.652 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.635 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   1.7s\n","[CV 4/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   1.7s\n","[CV 5/5] END LogRegClassifier__l1_ratio=0.5, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.663 total time=   1.7s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=nan total time=   0.3s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=nan total time=   0.9s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.5s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l1, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=nan total time=   1.6s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.889 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.881 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.887 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.876 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 1);, score=0.883 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.883 total time=   1.1s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.888 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.879 total time=   1.1s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 2);, score=0.885 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.883 total time=   1.9s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.888 total time=   1.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.879 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=100, WordWeightning__ngram_range=(1, 3);, score=0.885 total time=   1.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.781 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.764 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.770 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.780 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 1);, score=0.783 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.781 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.764 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.770 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.780 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 2);, score=0.783 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.781 total time=   1.8s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.764 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.770 total time=   1.8s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.780 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=500, WordWeightning__ngram_range=(1, 3);, score=0.783 total time=   1.8s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.652 total time=   0.4s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.635 total time=   0.4s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.4s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.653 total time=   0.4s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 1);, score=0.663 total time=   0.4s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.652 total time=   1.0s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.635 total time=   1.0s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.653 total time=   1.0s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 2);, score=0.663 total time=   1.0s\n","[CV 1/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.652 total time=   1.7s\n","[CV 2/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.635 total time=   1.8s\n","[CV 3/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   1.7s\n","[CV 4/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.653 total time=   1.8s\n","[CV 5/5] END LogRegClassifier__l1_ratio=1.0, LogRegClassifier__penalty=l2, WordWeightning__min_df=1000, WordWeightning__ngram_range=(1, 3);, score=0.663 total time=   1.8s\n","CPU times: user 4min 30s, sys: 3.87 s, total: 4min 34s\n","Wall time: 4min 37s\n"]}]},{"cell_type":"code","source":["# Report the standart deviation of split scores for each hyperparameter group.\n","\n","grid_scores = pd.DataFrame(clf.cv_results_)\n","grid_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MbauKc8otrSq","outputId":"15b3d8b3-46b7-4411-9a2e-19a01469765c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0        0.295154      0.015819         0.000000        0.000000   \n","1        0.856714      0.017048         0.000000        0.000000   \n","2        1.540328      0.019434         0.000000        0.000000   \n","3        0.285468      0.005667         0.000000        0.000000   \n","4        0.863756      0.009106         0.000000        0.000000   \n","5        1.754073      0.410205         0.000000        0.000000   \n","6        0.660408      0.166928         0.000000        0.000000   \n","7        0.847721      0.009423         0.000000        0.000000   \n","8        1.533331      0.013892         0.000000        0.000000   \n","9        0.350106      0.006987         0.062431        0.002206   \n","10       0.933555      0.018043         0.126044        0.003036   \n","11       1.630890      0.025750         0.197170        0.003776   \n","12       0.316960      0.008386         0.062550        0.006305   \n","13       0.882073      0.010380         0.119569        0.002171   \n","14       1.570388      0.018146         0.187367        0.007260   \n","15       0.297441      0.009520         0.057932        0.005214   \n","16       0.880359      0.010167         0.117132        0.002517   \n","17       1.718701      0.320451         0.187899        0.008774   \n","18       0.285438      0.005436         0.000000        0.000000   \n","19       0.862557      0.012700         0.000000        0.000000   \n","20       1.540810      0.019248         0.000000        0.000000   \n","21       0.277648      0.006040         0.000000        0.000000   \n","22       0.849502      0.011598         0.000000        0.000000   \n","23       1.537654      0.023923         0.000000        0.000000   \n","24       0.286815      0.013917         0.000000        0.000000   \n","25       0.859371      0.015006         0.000000        0.000000   \n","26       1.549339      0.008922         0.000000        0.000000   \n","27       0.344238      0.013271         0.060980        0.001692   \n","28       0.926099      0.011790         0.126781        0.006232   \n","29       1.611063      0.027263         0.194345        0.006703   \n","30       0.319606      0.006066         0.062730        0.004564   \n","31       0.907149      0.013743         0.122249        0.003860   \n","32       1.576924      0.015186         0.185980        0.006319   \n","33       0.299047      0.006052         0.057828        0.002910   \n","34       0.881936      0.013165         0.118007        0.002216   \n","35       1.554231      0.016424         0.184760        0.006638   \n","36       0.287946      0.013411         0.000000        0.000000   \n","37       0.900464      0.024357         0.000000        0.000000   \n","38       1.572930      0.023219         0.000000        0.000000   \n","39       0.281437      0.007413         0.000000        0.000000   \n","40       0.869281      0.010479         0.000000        0.000000   \n","41       1.538149      0.017161         0.000000        0.000000   \n","42       0.282044      0.004130         0.000000        0.000000   \n","43       0.852581      0.008883         0.000000        0.000000   \n","44       1.552496      0.006176         0.000000        0.000000   \n","45       0.341669      0.008529         0.063903        0.008298   \n","46       0.923378      0.011115         0.124587        0.003428   \n","47       1.619105      0.039255         0.193400        0.009449   \n","48       0.314712      0.002244         0.061472        0.004132   \n","49       0.907881      0.015455         0.121444        0.004362   \n","50       1.590483      0.012126         0.186972        0.007350   \n","51       0.301801      0.005496         0.057662        0.003105   \n","52       0.890453      0.012741         0.119891        0.002139   \n","53       1.593469      0.039038         0.190114        0.004928   \n","\n","   param_LogRegClassifier__l1_ratio param_LogRegClassifier__penalty  \\\n","0                               0.0                              l1   \n","1                               0.0                              l1   \n","2                               0.0                              l1   \n","3                               0.0                              l1   \n","4                               0.0                              l1   \n","5                               0.0                              l1   \n","6                               0.0                              l1   \n","7                               0.0                              l1   \n","8                               0.0                              l1   \n","9                               0.0                              l2   \n","10                              0.0                              l2   \n","11                              0.0                              l2   \n","12                              0.0                              l2   \n","13                              0.0                              l2   \n","14                              0.0                              l2   \n","15                              0.0                              l2   \n","16                              0.0                              l2   \n","17                              0.0                              l2   \n","18                              0.5                              l1   \n","19                              0.5                              l1   \n","20                              0.5                              l1   \n","21                              0.5                              l1   \n","22                              0.5                              l1   \n","23                              0.5                              l1   \n","24                              0.5                              l1   \n","25                              0.5                              l1   \n","26                              0.5                              l1   \n","27                              0.5                              l2   \n","28                              0.5                              l2   \n","29                              0.5                              l2   \n","30                              0.5                              l2   \n","31                              0.5                              l2   \n","32                              0.5                              l2   \n","33                              0.5                              l2   \n","34                              0.5                              l2   \n","35                              0.5                              l2   \n","36                              1.0                              l1   \n","37                              1.0                              l1   \n","38                              1.0                              l1   \n","39                              1.0                              l1   \n","40                              1.0                              l1   \n","41                              1.0                              l1   \n","42                              1.0                              l1   \n","43                              1.0                              l1   \n","44                              1.0                              l1   \n","45                              1.0                              l2   \n","46                              1.0                              l2   \n","47                              1.0                              l2   \n","48                              1.0                              l2   \n","49                              1.0                              l2   \n","50                              1.0                              l2   \n","51                              1.0                              l2   \n","52                              1.0                              l2   \n","53                              1.0                              l2   \n","\n","   param_WordWeightning__min_df param_WordWeightning__ngram_range  \\\n","0                           100                            (1, 1)   \n","1                           100                            (1, 2)   \n","2                           100                            (1, 3)   \n","3                           500                            (1, 1)   \n","4                           500                            (1, 2)   \n","5                           500                            (1, 3)   \n","6                          1000                            (1, 1)   \n","7                          1000                            (1, 2)   \n","8                          1000                            (1, 3)   \n","9                           100                            (1, 1)   \n","10                          100                            (1, 2)   \n","11                          100                            (1, 3)   \n","12                          500                            (1, 1)   \n","13                          500                            (1, 2)   \n","14                          500                            (1, 3)   \n","15                         1000                            (1, 1)   \n","16                         1000                            (1, 2)   \n","17                         1000                            (1, 3)   \n","18                          100                            (1, 1)   \n","19                          100                            (1, 2)   \n","20                          100                            (1, 3)   \n","21                          500                            (1, 1)   \n","22                          500                            (1, 2)   \n","23                          500                            (1, 3)   \n","24                         1000                            (1, 1)   \n","25                         1000                            (1, 2)   \n","26                         1000                            (1, 3)   \n","27                          100                            (1, 1)   \n","28                          100                            (1, 2)   \n","29                          100                            (1, 3)   \n","30                          500                            (1, 1)   \n","31                          500                            (1, 2)   \n","32                          500                            (1, 3)   \n","33                         1000                            (1, 1)   \n","34                         1000                            (1, 2)   \n","35                         1000                            (1, 3)   \n","36                          100                            (1, 1)   \n","37                          100                            (1, 2)   \n","38                          100                            (1, 3)   \n","39                          500                            (1, 1)   \n","40                          500                            (1, 2)   \n","41                          500                            (1, 3)   \n","42                         1000                            (1, 1)   \n","43                         1000                            (1, 2)   \n","44                         1000                            (1, 3)   \n","45                          100                            (1, 1)   \n","46                          100                            (1, 2)   \n","47                          100                            (1, 3)   \n","48                          500                            (1, 1)   \n","49                          500                            (1, 2)   \n","50                          500                            (1, 3)   \n","51                         1000                            (1, 1)   \n","52                         1000                            (1, 2)   \n","53                         1000                            (1, 3)   \n","\n","                                               params  split0_test_score  \\\n","0   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","1   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","2   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","3   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","4   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","5   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","6   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","7   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","8   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","9   {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.889013   \n","10  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.888312   \n","11  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.888312   \n","12  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.780961   \n","13  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.780961   \n","14  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.780961   \n","15  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.652052   \n","16  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.652052   \n","17  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...           0.652052   \n","18  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","19  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","20  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","21  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","22  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","23  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","24  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","25  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","26  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...                NaN   \n","27  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.889013   \n","28  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.888312   \n","29  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.888312   \n","30  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.780961   \n","31  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.780961   \n","32  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.780961   \n","33  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.652052   \n","34  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.652052   \n","35  {'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...           0.652052   \n","36  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","37  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","38  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","39  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","40  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","41  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","42  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","43  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","44  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...                NaN   \n","45  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.889013   \n","46  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.888312   \n","47  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.888312   \n","48  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.780961   \n","49  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.780961   \n","50  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.780961   \n","51  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.652052   \n","52  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.652052   \n","53  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.652052   \n","\n","    split1_test_score  split2_test_score  split3_test_score  \\\n","0                 NaN                NaN                NaN   \n","1                 NaN                NaN                NaN   \n","2                 NaN                NaN                NaN   \n","3                 NaN                NaN                NaN   \n","4                 NaN                NaN                NaN   \n","5                 NaN                NaN                NaN   \n","6                 NaN                NaN                NaN   \n","7                 NaN                NaN                NaN   \n","8                 NaN                NaN                NaN   \n","9            0.880557           0.886854           0.876346   \n","10           0.883351           0.887550           0.879159   \n","11           0.883351           0.887550           0.879159   \n","12           0.763783           0.769887           0.779881   \n","13           0.763783           0.769887           0.779881   \n","14           0.763783           0.769887           0.779881   \n","15           0.635313           0.652905           0.653251   \n","16           0.635313           0.652905           0.653251   \n","17           0.635313           0.652905           0.653251   \n","18                NaN                NaN                NaN   \n","19                NaN                NaN                NaN   \n","20                NaN                NaN                NaN   \n","21                NaN                NaN                NaN   \n","22                NaN                NaN                NaN   \n","23                NaN                NaN                NaN   \n","24                NaN                NaN                NaN   \n","25                NaN                NaN                NaN   \n","26                NaN                NaN                NaN   \n","27           0.880557           0.886854           0.876346   \n","28           0.883351           0.887550           0.879159   \n","29           0.883351           0.887550           0.879159   \n","30           0.763783           0.769887           0.779881   \n","31           0.763783           0.769887           0.779881   \n","32           0.763783           0.769887           0.779881   \n","33           0.635313           0.652905           0.653251   \n","34           0.635313           0.652905           0.653251   \n","35           0.635313           0.652905           0.653251   \n","36                NaN                NaN                NaN   \n","37                NaN                NaN                NaN   \n","38                NaN                NaN                NaN   \n","39                NaN                NaN                NaN   \n","40                NaN                NaN                NaN   \n","41                NaN                NaN                NaN   \n","42                NaN                NaN                NaN   \n","43                NaN                NaN                NaN   \n","44                NaN                NaN                NaN   \n","45           0.880557           0.886854           0.876346   \n","46           0.883351           0.887550           0.879159   \n","47           0.883351           0.887550           0.879159   \n","48           0.763783           0.769887           0.779881   \n","49           0.763783           0.769887           0.779881   \n","50           0.763783           0.769887           0.779881   \n","51           0.635313           0.652905           0.653251   \n","52           0.635313           0.652905           0.653251   \n","53           0.635313           0.652905           0.653251   \n","\n","    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n","0                 NaN              NaN             NaN               37  \n","1                 NaN              NaN             NaN               39  \n","2                 NaN              NaN             NaN               40  \n","3                 NaN              NaN             NaN               41  \n","4                 NaN              NaN             NaN               42  \n","5                 NaN              NaN             NaN               43  \n","6                 NaN              NaN             NaN               44  \n","7                 NaN              NaN             NaN               46  \n","8                 NaN              NaN             NaN               53  \n","9            0.883265         0.883207        0.004497                7  \n","10           0.885346         0.884744        0.003289                1  \n","11           0.885346         0.884744        0.003289                1  \n","12           0.782587         0.775420        0.007321               10  \n","13           0.782587         0.775420        0.007321               10  \n","14           0.782587         0.775420        0.007321               10  \n","15           0.663475         0.651399        0.009063               19  \n","16           0.663475         0.651399        0.009063               19  \n","17           0.663475         0.651399        0.009063               19  \n","18                NaN              NaN             NaN               47  \n","19                NaN              NaN             NaN               48  \n","20                NaN              NaN             NaN               49  \n","21                NaN              NaN             NaN               50  \n","22                NaN              NaN             NaN               51  \n","23                NaN              NaN             NaN               52  \n","24                NaN              NaN             NaN               38  \n","25                NaN              NaN             NaN               45  \n","26                NaN              NaN             NaN               54  \n","27           0.883265         0.883207        0.004497                7  \n","28           0.885346         0.884744        0.003289                1  \n","29           0.885346         0.884744        0.003289                1  \n","30           0.782587         0.775420        0.007321               10  \n","31           0.782587         0.775420        0.007321               10  \n","32           0.782587         0.775420        0.007321               10  \n","33           0.663475         0.651399        0.009063               19  \n","34           0.663475         0.651399        0.009063               19  \n","35           0.663475         0.651399        0.009063               19  \n","36                NaN              NaN             NaN               31  \n","37                NaN              NaN             NaN               30  \n","38                NaN              NaN             NaN               29  \n","39                NaN              NaN             NaN               28  \n","40                NaN              NaN             NaN               36  \n","41                NaN              NaN             NaN               32  \n","42                NaN              NaN             NaN               33  \n","43                NaN              NaN             NaN               34  \n","44                NaN              NaN             NaN               35  \n","45           0.883265         0.883207        0.004497                7  \n","46           0.885346         0.884744        0.003289                1  \n","47           0.885346         0.884744        0.003289                1  \n","48           0.782587         0.775420        0.007321               10  \n","49           0.782587         0.775420        0.007321               10  \n","50           0.782587         0.775420        0.007321               10  \n","51           0.663475         0.651399        0.009063               19  \n","52           0.663475         0.651399        0.009063               19  \n","53           0.663475         0.651399        0.009063               19  "],"text/html":["\n","  <div id=\"df-4d784488-4aac-4b93-a530-9104d7fa5483\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_LogRegClassifier__l1_ratio</th>\n","      <th>param_LogRegClassifier__penalty</th>\n","      <th>param_WordWeightning__min_df</th>\n","      <th>param_WordWeightning__ngram_range</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.295154</td>\n","      <td>0.015819</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.856714</td>\n","      <td>0.017048</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.540328</td>\n","      <td>0.019434</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.285468</td>\n","      <td>0.005667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.863756</td>\n","      <td>0.009106</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.754073</td>\n","      <td>0.410205</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.660408</td>\n","      <td>0.166928</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.847721</td>\n","      <td>0.009423</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.533331</td>\n","      <td>0.013892</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.350106</td>\n","      <td>0.006987</td>\n","      <td>0.062431</td>\n","      <td>0.002206</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.889013</td>\n","      <td>0.880557</td>\n","      <td>0.886854</td>\n","      <td>0.876346</td>\n","      <td>0.883265</td>\n","      <td>0.883207</td>\n","      <td>0.004497</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.933555</td>\n","      <td>0.018043</td>\n","      <td>0.126044</td>\n","      <td>0.003036</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.630890</td>\n","      <td>0.025750</td>\n","      <td>0.197170</td>\n","      <td>0.003776</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.316960</td>\n","      <td>0.008386</td>\n","      <td>0.062550</td>\n","      <td>0.006305</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.882073</td>\n","      <td>0.010380</td>\n","      <td>0.119569</td>\n","      <td>0.002171</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1.570388</td>\n","      <td>0.018146</td>\n","      <td>0.187367</td>\n","      <td>0.007260</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.297441</td>\n","      <td>0.009520</td>\n","      <td>0.057932</td>\n","      <td>0.005214</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.880359</td>\n","      <td>0.010167</td>\n","      <td>0.117132</td>\n","      <td>0.002517</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1.718701</td>\n","      <td>0.320451</td>\n","      <td>0.187899</td>\n","      <td>0.008774</td>\n","      <td>0.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.285438</td>\n","      <td>0.005436</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.862557</td>\n","      <td>0.012700</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>1.540810</td>\n","      <td>0.019248</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.277648</td>\n","      <td>0.006040</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.849502</td>\n","      <td>0.011598</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1.537654</td>\n","      <td>0.023923</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.286815</td>\n","      <td>0.013917</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.859371</td>\n","      <td>0.015006</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>1.549339</td>\n","      <td>0.008922</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.5</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.344238</td>\n","      <td>0.013271</td>\n","      <td>0.060980</td>\n","      <td>0.001692</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.889013</td>\n","      <td>0.880557</td>\n","      <td>0.886854</td>\n","      <td>0.876346</td>\n","      <td>0.883265</td>\n","      <td>0.883207</td>\n","      <td>0.004497</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.926099</td>\n","      <td>0.011790</td>\n","      <td>0.126781</td>\n","      <td>0.006232</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1.611063</td>\n","      <td>0.027263</td>\n","      <td>0.194345</td>\n","      <td>0.006703</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.319606</td>\n","      <td>0.006066</td>\n","      <td>0.062730</td>\n","      <td>0.004564</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.907149</td>\n","      <td>0.013743</td>\n","      <td>0.122249</td>\n","      <td>0.003860</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>1.576924</td>\n","      <td>0.015186</td>\n","      <td>0.185980</td>\n","      <td>0.006319</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.299047</td>\n","      <td>0.006052</td>\n","      <td>0.057828</td>\n","      <td>0.002910</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.881936</td>\n","      <td>0.013165</td>\n","      <td>0.118007</td>\n","      <td>0.002216</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>1.554231</td>\n","      <td>0.016424</td>\n","      <td>0.184760</td>\n","      <td>0.006638</td>\n","      <td>0.5</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.5, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.287946</td>\n","      <td>0.013411</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.900464</td>\n","      <td>0.024357</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>1.572930</td>\n","      <td>0.023219</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.281437</td>\n","      <td>0.007413</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.869281</td>\n","      <td>0.010479</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>1.538149</td>\n","      <td>0.017161</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.282044</td>\n","      <td>0.004130</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.852581</td>\n","      <td>0.008883</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>1.552496</td>\n","      <td>0.006176</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>l1</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.341669</td>\n","      <td>0.008529</td>\n","      <td>0.063903</td>\n","      <td>0.008298</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.889013</td>\n","      <td>0.880557</td>\n","      <td>0.886854</td>\n","      <td>0.876346</td>\n","      <td>0.883265</td>\n","      <td>0.883207</td>\n","      <td>0.004497</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.923378</td>\n","      <td>0.011115</td>\n","      <td>0.124587</td>\n","      <td>0.003428</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>1.619105</td>\n","      <td>0.039255</td>\n","      <td>0.193400</td>\n","      <td>0.009449</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.888312</td>\n","      <td>0.883351</td>\n","      <td>0.887550</td>\n","      <td>0.879159</td>\n","      <td>0.885346</td>\n","      <td>0.884744</td>\n","      <td>0.003289</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.314712</td>\n","      <td>0.002244</td>\n","      <td>0.061472</td>\n","      <td>0.004132</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.907881</td>\n","      <td>0.015455</td>\n","      <td>0.121444</td>\n","      <td>0.004362</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>1.590483</td>\n","      <td>0.012126</td>\n","      <td>0.186972</td>\n","      <td>0.007350</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.780961</td>\n","      <td>0.763783</td>\n","      <td>0.769887</td>\n","      <td>0.779881</td>\n","      <td>0.782587</td>\n","      <td>0.775420</td>\n","      <td>0.007321</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>0.301801</td>\n","      <td>0.005496</td>\n","      <td>0.057662</td>\n","      <td>0.003105</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0.890453</td>\n","      <td>0.012741</td>\n","      <td>0.119891</td>\n","      <td>0.002139</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>1.593469</td>\n","      <td>0.039038</td>\n","      <td>0.190114</td>\n","      <td>0.004928</td>\n","      <td>1.0</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.652052</td>\n","      <td>0.635313</td>\n","      <td>0.652905</td>\n","      <td>0.653251</td>\n","      <td>0.663475</td>\n","      <td>0.651399</td>\n","      <td>0.009063</td>\n","      <td>19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d784488-4aac-4b93-a530-9104d7fa5483')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4d784488-4aac-4b93-a530-9104d7fa5483 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4d784488-4aac-4b93-a530-9104d7fa5483');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["# Show the best parameter set for given dataset and hyperparameter space.\n","\n","print(\"Best Score: \", clf.best_score_)\n","print(\"Best Hyperparameters: \", clf.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZN4BHMOsnxW","outputId":"1af441e6-dd62-4468-9e64-567f268fc9ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score:  0.8847436551308672\n","Best Hyperparameters:  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegClassifier__penalty': 'l2', 'WordWeightning__min_df': 100, 'WordWeightning__ngram_range': (1, 2)}\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #\n","# Create your Pipeline object with the best parameter set.\n","\n","logistic_regression_components = [('WordWeightning' ,TfidfVectorizer(analyzer = 'word' , min_df = 100, ngram_range=(1,2))), ('LogRegClassifier', LogisticRegression(random_state = 22 , penalty = \"l2\"))]\n","logistic_regression_pipeline = Pipeline(logistic_regression_components)\n","\n","\n","\n","# Fit your pipeline on training set.\n","\n","logistic_regression_pipeline.fit(binary_train_x, binary_train_y)\n","\n","# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.\n","pred_y= logistic_regression_pipeline.predict(binary_test_x)\n","\n","f1_score = f1_score(binary_test_y,pred_y)\n","acc_score = accuracy_score(binary_test_y, pred_y)\n","print(\"F1 Score: \", f1_score)\n","print(\"Accuracy Score: \", acc_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0Ah56MfuQla","outputId":"6dbc0b4a-5ff3-4a29-fe54-0eda408248d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score:  0.8899876390605687\n","Accuracy Score:  0.8903940886699507\n"]}]},{"cell_type":"code","source":["#Confusion Matrix\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cf_matrix = confusion_matrix(binary_test_y, pred_y)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n","                              display_labels= logistic_regression_pipeline.classes_)\n","disp.plot()\n","\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"w0y1DuMmHSMd","outputId":"bd5992cc-089f-4102-a769-88d5b114619b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["#### Multiclass"],"metadata":{"id":"xgy8BLNaTRfZ"}},{"cell_type":"code","source":["multi_logistic_regression_components = [('WordWeightning' ,TfidfVectorizer(analyzer = 'word')), ('LogRegClassifier', LogisticRegression(random_state = 22))]\n","multi_logistic_regression_pipeline = Pipeline(multi_logistic_regression_components)\n","\n","\n","\n","#Set the hyperparameter space that will be scanned.\n","multi_logreg_grid_parameters =  {\n","    'WordWeightning__ngram_range' : [(1,1) , (1,2), (1,3)],\n","    'WordWeightning__min_df' : [100, 500, 1000],\n","    'LogRegClassifier__penalty' : ['l1' , 'l2'],\n","    'LogRegClassifier__l1_ratio' : [0.0, 0.5, 1.0],\n","    'LogRegClassifier__multi_class' : ['auto', 'multinomial']\n","\n","}"],"metadata":{"id":"nkckb488LL7x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for multiclass classification.\n","clf = GridSearchCV(multi_logistic_regression_pipeline, multi_logreg_grid_parameters,verbose = 0, scoring='f1_macro')\n","clf.fit(multiclass_train_x, multiclass_train_y)\n"],"metadata":{"id":"kRYqtWiP2Gg6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd2296f7-5016-412e-c43f-4c3cb1abba2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 13min 59s, sys: 14 s, total: 14min 13s\n","Wall time: 14min 16s\n"]}]},{"cell_type":"code","source":["# Report the standart deviation of split scores for each hyperparameter group.\n","\n","grid_scores = pd.DataFrame(clf.cv_results_)\n","grid_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":661},"id":"Ej22K1SWIAyN","outputId":"19ce2b18-8d7b-47c9-cf0d-012e22f995a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0         0.361344      0.010056         0.000000        0.000000   \n","1         1.270264      0.196816         0.000000        0.000000   \n","2         2.260632      0.245077         0.000000        0.000000   \n","3         0.353533      0.004049         0.000000        0.000000   \n","4         1.137413      0.012087         0.000000        0.000000   \n","..             ...           ...              ...             ...   \n","103       1.677034      0.012815         0.164437        0.006322   \n","104       2.547796      0.015826         0.247220        0.007283   \n","105       0.558335      0.017819         0.071403        0.002026   \n","106       1.328657      0.029059         0.153369        0.006237   \n","107       2.192348      0.033889         0.238752        0.007915   \n","\n","    param_LogRegClassifier__l1_ratio param_LogRegClassifier__multi_class  \\\n","0                                0.0                                auto   \n","1                                0.0                                auto   \n","2                                0.0                                auto   \n","3                                0.0                                auto   \n","4                                0.0                                auto   \n","..                               ...                                 ...   \n","103                              1.0                         multinomial   \n","104                              1.0                         multinomial   \n","105                              1.0                         multinomial   \n","106                              1.0                         multinomial   \n","107                              1.0                         multinomial   \n","\n","    param_LogRegClassifier__penalty param_WordWeightning__min_df  \\\n","0                                l1                          100   \n","1                                l1                          100   \n","2                                l1                          100   \n","3                                l1                          500   \n","4                                l1                          500   \n","..                              ...                          ...   \n","103                              l2                          500   \n","104                              l2                          500   \n","105                              l2                         1000   \n","106                              l2                         1000   \n","107                              l2                         1000   \n","\n","    param_WordWeightning__ngram_range  \\\n","0                              (1, 1)   \n","1                              (1, 2)   \n","2                              (1, 3)   \n","3                              (1, 1)   \n","4                              (1, 2)   \n","..                                ...   \n","103                            (1, 2)   \n","104                            (1, 3)   \n","105                            (1, 1)   \n","106                            (1, 2)   \n","107                            (1, 3)   \n","\n","                                                params  split0_test_score  \\\n","0    {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","1    {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","2    {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","3    {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","4    {'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...                NaN   \n","..                                                 ...                ...   \n","103  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.443675   \n","104  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.443675   \n","105  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.346295   \n","106  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.346295   \n","107  {'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...           0.346295   \n","\n","     split1_test_score  split2_test_score  split3_test_score  \\\n","0                  NaN                NaN                NaN   \n","1                  NaN                NaN                NaN   \n","2                  NaN                NaN                NaN   \n","3                  NaN                NaN                NaN   \n","4                  NaN                NaN                NaN   \n","..                 ...                ...                ...   \n","103           0.456564           0.448961           0.423519   \n","104           0.456564           0.448961           0.423519   \n","105           0.333591           0.332611           0.328795   \n","106           0.333591           0.332611           0.328795   \n","107           0.333591           0.332611           0.328795   \n","\n","     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n","0                  NaN              NaN             NaN              108  \n","1                  NaN              NaN             NaN               77  \n","2                  NaN              NaN             NaN               76  \n","3                  NaN              NaN             NaN               75  \n","4                  NaN              NaN             NaN               74  \n","..                 ...              ...             ...              ...  \n","103           0.429889         0.440521        0.012171               19  \n","104           0.429889         0.440521        0.012171               19  \n","105           0.336503         0.335559        0.005907               37  \n","106           0.336503         0.335559        0.005907               37  \n","107           0.336503         0.335559        0.005907               37  \n","\n","[108 rows x 18 columns]"],"text/html":["\n","  <div id=\"df-31b5792b-06e1-48fc-8708-2bc17e815c1c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_LogRegClassifier__l1_ratio</th>\n","      <th>param_LogRegClassifier__multi_class</th>\n","      <th>param_LogRegClassifier__penalty</th>\n","      <th>param_WordWeightning__min_df</th>\n","      <th>param_WordWeightning__ngram_range</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.361344</td>\n","      <td>0.010056</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>auto</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>108</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.270264</td>\n","      <td>0.196816</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>auto</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.260632</td>\n","      <td>0.245077</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>auto</td>\n","      <td>l1</td>\n","      <td>100</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.353533</td>\n","      <td>0.004049</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>auto</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.137413</td>\n","      <td>0.012087</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>auto</td>\n","      <td>l1</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 0.0, 'LogRegCla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>1.677034</td>\n","      <td>0.012815</td>\n","      <td>0.164437</td>\n","      <td>0.006322</td>\n","      <td>1.0</td>\n","      <td>multinomial</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.443675</td>\n","      <td>0.456564</td>\n","      <td>0.448961</td>\n","      <td>0.423519</td>\n","      <td>0.429889</td>\n","      <td>0.440521</td>\n","      <td>0.012171</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>2.547796</td>\n","      <td>0.015826</td>\n","      <td>0.247220</td>\n","      <td>0.007283</td>\n","      <td>1.0</td>\n","      <td>multinomial</td>\n","      <td>l2</td>\n","      <td>500</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.443675</td>\n","      <td>0.456564</td>\n","      <td>0.448961</td>\n","      <td>0.423519</td>\n","      <td>0.429889</td>\n","      <td>0.440521</td>\n","      <td>0.012171</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>0.558335</td>\n","      <td>0.017819</td>\n","      <td>0.071403</td>\n","      <td>0.002026</td>\n","      <td>1.0</td>\n","      <td>multinomial</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 1)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.346295</td>\n","      <td>0.333591</td>\n","      <td>0.332611</td>\n","      <td>0.328795</td>\n","      <td>0.336503</td>\n","      <td>0.335559</td>\n","      <td>0.005907</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>1.328657</td>\n","      <td>0.029059</td>\n","      <td>0.153369</td>\n","      <td>0.006237</td>\n","      <td>1.0</td>\n","      <td>multinomial</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 2)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.346295</td>\n","      <td>0.333591</td>\n","      <td>0.332611</td>\n","      <td>0.328795</td>\n","      <td>0.336503</td>\n","      <td>0.335559</td>\n","      <td>0.005907</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>2.192348</td>\n","      <td>0.033889</td>\n","      <td>0.238752</td>\n","      <td>0.007915</td>\n","      <td>1.0</td>\n","      <td>multinomial</td>\n","      <td>l2</td>\n","      <td>1000</td>\n","      <td>(1, 3)</td>\n","      <td>{'LogRegClassifier__l1_ratio': 1.0, 'LogRegCla...</td>\n","      <td>0.346295</td>\n","      <td>0.333591</td>\n","      <td>0.332611</td>\n","      <td>0.328795</td>\n","      <td>0.336503</td>\n","      <td>0.335559</td>\n","      <td>0.005907</td>\n","      <td>37</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>108 rows × 18 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b5792b-06e1-48fc-8708-2bc17e815c1c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-31b5792b-06e1-48fc-8708-2bc17e815c1c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-31b5792b-06e1-48fc-8708-2bc17e815c1c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Show the best parameter set for given dataset and hyperparameter space.\n","\n","print(\"Best Score: \", clf.best_score_)\n","print(\"Best Hyperparameters: \", clf.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vxJNMSRPgfI","outputId":"722d570b-10db-49ec-c7ab-2c531a381f8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score:  0.5108437884395868\n","Best Hyperparameters:  {'LogRegClassifier__l1_ratio': 0.0, 'LogRegClassifier__multi_class': 'auto', 'LogRegClassifier__penalty': 'l2', 'WordWeightning__min_df': 100, 'WordWeightning__ngram_range': (1, 2)}\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #\n","# Create your Pipeline object with the best parameter set.\n","\n","multi_logistic_regression_components = [('WordWeightning' ,TfidfVectorizer(analyzer = 'word' , min_df = 100, ngram_range=(1,2))), ('LogRegClassifier', LogisticRegression(random_state = 22 , penalty = \"l2\", multi_class='multinomial'))]\n","multi_logistic_regression_pipeline = Pipeline(multi_logistic_regression_components)\n","\n","\n","\n","# Fit your pipeline on training set.\n","\n","multi_logistic_regression_pipeline.fit(multiclass_train_x, multiclass_train_y)\n","\n","# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.\n","multiclass_pred_y= multi_logistic_regression_pipeline.predict(multiclass_test_x,)\n","\n","f1_score = f1_score(multiclass_test_y,multiclass_pred_y, average =\"macro\")\n","acc_score = accuracy_score(multiclass_test_y, multiclass_pred_y)\n","print(\"F1 Score: \", f1_score)\n","print(\"Accuracy Score: \", acc_score)"],"metadata":{"id":"jkSVZ2pHPkaj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0387b634-2007-4f4d-d7b0-e0b1df8ff01c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score:  0.5195094567239478\n","Accuracy Score:  0.523\n"]}]},{"cell_type":"code","source":["#Confusion Matrix\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cf_matrix = confusion_matrix(multiclass_test_y, pred_y)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n","                              display_labels= multi_logistic_regression_pipeline.classes_)\n","disp.plot()\n","\n","\n","plt.show()"],"metadata":{"id":"cIspyoiVBqQY","colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"d4bb4971-da5f-410f-ad9a-fbd3940e6abb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Neural Models"],"metadata":{"id":"ISxrqFKrh8Rb"}},{"cell_type":"markdown","source":["### Convolutional Neural Network (CNN)"],"metadata":{"id":"87S_VWH9h-JQ"}},{"cell_type":"markdown","source":["-----Used Resources-----\n","\n","https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456\n","https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n","https://machinelearningmastery.com/best-practices-document-classification-deep-learning/"],"metadata":{"id":"ZrZFArkRCePU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import nltk,re\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from numpy import array,asarray,zeros\n","\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","import keras\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv1D,MaxPooling1D\n","from keras.layers import Dense,Flatten,Embedding,Input,Dropout\n","from keras.callbacks import ModelCheckpoint\n","\n","from gensim.models import Word2Vec\n","import gensim.downloader as api"],"metadata":{"id":"gw4QZK0biCrt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"825b144e-627e-4c6c-d724-7a04180476d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Create a validation set from train set\n","# Please use random_state of 22 and test_size of 0.1\n","\n","binary_validation = binary_train.sample(frac=0.1, random_state = 22)\n","binary_train = binary_train.drop(binary_validation.index)\n","\n","multiclass_validation = multiclass_train.sample(frac=0.1, random_state = 22)\n","multiclass_train= multiclass_train.drop(multiclass_validation.index)\n"],"metadata":{"id":"pwnZjYetJwO7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binary_train_corpus = list(binary_train['text'].str.split(' '))\n","multi_train_corpus = list(multiclass_train['text'].str.split(' '))"],"metadata":{"id":"za92YGONvwEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create your own word embeddings from scratch and load a pretrained word embeddings\n","\n","\n","\n","\n","\n","# You can check https://radimrehurek.com/gensim/models/word2vec.html for training a word embeddings from scratch\n","\n","binary_w2v_model = Word2Vec(sentences=binary_train_corpus, size = 100, window=5, min_count=1, workers=4)\n","multi_w2v_model = Word2Vec(sentences=multi_train_corpus, size = 100, window=5, min_count=1, workers=4)\n","\n","filename_binary =\"binary_w2v_model.txt\"\n","filename_multi = \"multi_w2v_model.txt\"\n","\n","binary_w2v_model.wv.save_word2vec_format(filename_binary, binary=False)\n","multi_w2v_model.wv.save_word2vec_format(filename_multi, binary=False)\n","\n","\n","\n","# You can check https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html and https://github.com/RaRe-Technologies/gensim-data for loading pretrained word embeddings. \n","\n","pretrained_embedding = api.load(\"glove-twitter-100\")\n","\n","\n"],"metadata":{"id":"cuitOMs3J2ax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save pretrained embedding\n","filename_pretrained = \"pretrained_embedding.txt\"\n","binary_w2v_model.wv.save_word2vec_format(filename_pretrained, binary=False)"],"metadata":{"id":"bPoP9EN__eVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare your dataset for CNN classifier\n","total_binary_reviews = list(binary_train['text'].values)  #+ list(binary_test['text'].values) + list(binary_validation['text'].values)\n","total_multiclass_reviews = list(multiclass_train['text']) #+ list(multiclass_test['text']) + list(multiclass_validation['text'])\n","\n","binary_tokenizer = Tokenizer(oov_token='OOV')\n","binary_tokenizer.fit_on_texts(total_binary_reviews)\n","\n","multi_tokenizer = Tokenizer(oov_token='OOV')\n","multi_tokenizer.fit_on_texts(multiclass_train.text)\n","\n","\n","binary_max_length = max([len(s.split()) for s in total_binary_reviews])\n","multi_max_length = max([len(s.split()) for s in total_multiclass_reviews])\n","\n"],"metadata":{"id":"5SFbFf8dKBf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Max length text in binary dataset: \", binary_max_length)\n","print(\"Max length text in multiclass dataset: \", multi_max_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-_sHlPATmn3","outputId":"2d0e6193-38c4-47c2-9587-71a22b522daa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max length text in binary dataset:  496\n","Max length text in multiclass dataset:  495\n"]}]},{"cell_type":"code","source":["binary_vocab_size = len(binary_tokenizer.word_index)+1\n","print(binary_vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHd10lWk_Ke1","outputId":"7efa3a19-b00c-4c0a-9e09-94f7882bc4c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23072\n"]}]},{"cell_type":"code","source":["multi_vocab_size = len(multi_tokenizer.word_index)+1\n","print(multi_vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u87iiIV7nY_O","outputId":"e3e80088-9928-4e90-e2ea-e2045494f6a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26550\n"]}]},{"cell_type":"code","source":["#tokenize the dataset\n","x_binary_train = binary_train['text'].values.tolist()\n","x_binary_train_tokens = binary_tokenizer.texts_to_sequences(x_binary_train)\n","y_binary_train = binary_train['label']\n","\n","x_binary_validation = binary_validation['text'].values.tolist()\n","x_binary_validation_tokens = binary_tokenizer.texts_to_sequences(x_binary_validation)\n","y_binary_validation = binary_validation['label']\n","\n","x_binary_test = list(binary_test['text'].values)\n","y_binary_test = binary_test['label']\n","x_binary_test_tokens = binary_tokenizer.texts_to_sequences(x_binary_test)\n","\n","x_multi_train = multiclass_train['text'].values.tolist()\n","x_multi_train_tokens = multi_tokenizer.texts_to_sequences(x_multi_train)\n","y_multi_train = multiclass_train['label']\n","\n","x_multi_validation = multiclass_validation['text'].values.tolist()\n","x_multi_validation_tokens = multi_tokenizer.texts_to_sequences(x_multi_validation)\n","y_multi_validation = multiclass_validation['label']\n","\n","x_multi_test = multiclass_test['text'].values.tolist()\n","x_multi_test_tokens = multi_tokenizer.texts_to_sequences(x_multi_test)\n","y_multi_test = multiclass_test['label']\n","\n","#padding\n","x_binary_train_pad = pad_sequences(x_binary_train_tokens, maxlen = binary_max_length, padding = 'post')\n","x_binary_test_pad = pad_sequences(x_binary_test_tokens, maxlen = binary_max_length, padding = 'post')\n","x_binary_validation_pad = pad_sequences(x_binary_validation_tokens, maxlen = binary_max_length, padding = 'post')\n","\n","x_multi_train_pad = pad_sequences(x_multi_train_tokens, maxlen = multi_max_length, padding = 'post')\n","x_multi_validation_pad = pad_sequences(x_multi_validation_tokens, maxlen = multi_max_length, padding = 'post')\n","x_multi_test_pad = pad_sequences(x_multi_test_tokens, maxlen = multi_max_length, padding = 'post')"],"metadata":{"id":"M1ldwU769TYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creating embedding matrix\n","import os\n","EMBEDDING_DIM = 100\n","\n","def create_embedding_matrix(filename, tokenizer):\n","  word_index = tokenizer.word_index\n","  num_words = len(word_index)+1\n","  embeddings_index={}\n","  f=open(os.path.join('',filename),encoding='utf-8')\n","\n","  for line in f:\n","    values=line.split()\n","    word=values[0]\n","    coefs=np.asarray(values[1:])\n","    embeddings_index[word]=coefs\n","  f.close()\n","  embedding_matrix=np.zeros((num_words,EMBEDDING_DIM))\n","  for word, i in word_index.items():\n","    if i>num_words:\n","      continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","      embedding_matrix[i]=embedding_vector\n","  return embedding_matrix\n","\n","#binary\n","binary_w2v_embedding_matrix = create_embedding_matrix(filename_binary, binary_tokenizer)\n","multi_w2c_embedding_matrix = create_embedding_matrix(filename_multi, multi_tokenizer)\n","\n","pretrained_embedding_matrix_binary = create_embedding_matrix(filename_pretrained,binary_tokenizer)\n","pretrained_embedding_matrix_multi = create_embedding_matrix(filename_pretrained,multi_tokenizer)"],"metadata":{"id":"UMnr8zKA7lrk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Neural Models for Binary Classification"],"metadata":{"id":"oK5AOQV4C8o0"}},{"cell_type":"markdown","source":["#####Randomly Initialized Word Embeddings"],"metadata":{"id":"hQZ9em9hG0KL"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import classification_report\n","\n","EMBEDDING_DIM = 100\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","      model_random_binary_1 = Sequential()\n","      model_random_binary_1.add(Embedding(binary_vocab_size, EMBEDDING_DIM, input_length = binary_max_length))\n","      model_random_binary_1.add(Conv1D(filters=f, kernel_size=k, activation='relu'))\n","      model_random_binary_1.add(MaxPooling1D(pool_size=2))\n","      model_random_binary_1.add(Flatten())\n","      model_random_binary_1.add(Dense(h, activation='relu'))\n","      model_random_binary_1.add(Dense(1, activation='sigmoid')) #using sigmoid because of binary classficiation\n","\n","      # compile network\n","      model_random_binary_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model_random_binary_1.fit(x_binary_train_pad, y_binary_train, epochs=8, verbose=0, validation_data=(x_binary_validation_pad, y_binary_validation))\n","\n","      loss, acc = model_random_binary_1.evaluate(x_binary_test_pad, y_binary_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model_random_binary_1.predict(x_binary_test_pad)\n","      predicted_classes = y_pred.astype(int).tolist()\n","      print(classification_report(y_binary_test, predicted_classes))\n","      print(\"*********************************\")\n","\n"],"metadata":{"id":"dTUUQw0aKKA4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c91b4ea6-6b8a-4864-c72d-a2ac1de04c5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26/26 [==============================] - 1s 23ms/step - loss: 0.6014 - accuracy: 0.8953\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 89.532018 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.55      1.00      0.71       401\n","           1       0.99      0.20      0.33       411\n","\n","    accuracy                           0.59       812\n","   macro avg       0.77      0.60      0.52       812\n","weighted avg       0.77      0.59      0.52       812\n","\n","*********************************\n","26/26 [==============================] - 1s 23ms/step - loss: 0.5622 - accuracy: 0.8941\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 89.408869 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.66       401\n","           1       1.00      0.01      0.03       411\n","\n","    accuracy                           0.50       812\n","   macro avg       0.75      0.51      0.35       812\n","weighted avg       0.75      0.50      0.34       812\n","\n","*********************************\n","26/26 [==============================] - 1s 38ms/step - loss: 0.6473 - accuracy: 0.8842\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 88.423645 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.51      1.00      0.68       401\n","           1       1.00      0.07      0.13       411\n","\n","    accuracy                           0.53       812\n","   macro avg       0.76      0.54      0.40       812\n","weighted avg       0.76      0.53      0.40       812\n","\n","*********************************\n","26/26 [==============================] - 1s 39ms/step - loss: 0.6606 - accuracy: 0.8892\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 88.916254 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.53      1.00      0.69       401\n","           1       1.00      0.14      0.25       411\n","\n","    accuracy                           0.57       812\n","   macro avg       0.77      0.57      0.47       812\n","weighted avg       0.77      0.57      0.47       812\n","\n","*********************************\n","26/26 [==============================] - 1s 36ms/step - loss: 0.5962 - accuracy: 0.8892\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 88.916254 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.66       401\n","           1       1.00      0.01      0.02       411\n","\n","    accuracy                           0.50       812\n","   macro avg       0.75      0.51      0.34       812\n","weighted avg       0.75      0.50      0.34       812\n","\n","*********************************\n","26/26 [==============================] - 1s 38ms/step - loss: 0.7970 - accuracy: 0.8879\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 88.793105 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.99      0.80       401\n","           1       0.98      0.53      0.69       411\n","\n","    accuracy                           0.75       812\n","   macro avg       0.82      0.76      0.74       812\n","weighted avg       0.83      0.75      0.74       812\n","\n","*********************************\n","26/26 [==============================] - 2s 66ms/step - loss: 0.4401 - accuracy: 0.8805\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 88.054186 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.56      1.00      0.71       401\n","           1       0.99      0.23      0.37       411\n","\n","    accuracy                           0.61       812\n","   macro avg       0.77      0.61      0.54       812\n","weighted avg       0.78      0.61      0.54       812\n","\n","*********************************\n","26/26 [==============================] - 2s 65ms/step - loss: 0.6525 - accuracy: 0.8744\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 87.438422 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.52      1.00      0.68       401\n","           1       0.97      0.09      0.17       411\n","\n","    accuracy                           0.54       812\n","   macro avg       0.75      0.54      0.43       812\n","weighted avg       0.75      0.54      0.42       812\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["#####Word2Vec Embedding"],"metadata":{"id":"eCwE91i3gkYY"}},{"cell_type":"code","source":["#Creating embedding matrices and layers\n","\n","w2v_binary_embedding_layer = Embedding(len(binary_tokenizer.word_index)+1,  EMBEDDING_DIM ,weights = [binary_w2v_embedding_matrix],input_length = binary_max_length)\n","\n","EMBEDDING_DIM = 100\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","\n","      model = Sequential()\n","      model.add(w2v_binary_embedding_layer)\n","      model.add(Conv1D(filters=f, kernel_size=k, activation='relu'))\n","      model.add(MaxPooling1D(pool_size=2))\n","      model.add(Flatten())\n","      model.add(Dense(h, activation='relu'))\n","      model.add(Dense(1, activation='sigmoid')) #using sigmoid because of binary classficiation\n","      # compile network\n","      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model.fit(x_binary_train_pad, y_binary_train, epochs=8,verbose= 0, validation_data=(x_binary_validation_pad, y_binary_validation))\n","      loss, acc = model.evaluate(x_binary_test_pad, y_binary_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model.predict(x_binary_test_pad)\n","      predicted_classes = y_pred.astype(int).tolist()\n","      print(classification_report(y_binary_test, predicted_classes))\n","      print(\"*********************************\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vR8mGab7gtIQ","outputId":"92124ab8-927e-4fb0-ba36-e32094fe5823"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26/26 [==============================] - 1s 22ms/step - loss: 0.5521 - accuracy: 0.8916\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 89.162564 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.56      1.00      0.72       401\n","           1       0.99      0.25      0.40       411\n","\n","    accuracy                           0.62       812\n","   macro avg       0.78      0.62      0.56       812\n","weighted avg       0.78      0.62      0.56       812\n","\n","*********************************\n","26/26 [==============================] - 1s 21ms/step - loss: 0.7648 - accuracy: 0.8916\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 89.162564 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.99      0.78       401\n","           1       0.97      0.47      0.63       411\n","\n","    accuracy                           0.73       812\n","   macro avg       0.81      0.73      0.71       812\n","weighted avg       0.81      0.73      0.71       812\n","\n","*********************************\n","26/26 [==============================] - 1s 38ms/step - loss: 0.7137 - accuracy: 0.8855\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 88.546801 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       401\n","           1       0.99      0.36      0.53       411\n","\n","    accuracy                           0.67       812\n","   macro avg       0.80      0.68      0.64       812\n","weighted avg       0.80      0.67      0.64       812\n","\n","*********************************\n","26/26 [==============================] - 1s 37ms/step - loss: 0.8984 - accuracy: 0.8916\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 89.162564 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.98      0.79       401\n","           1       0.97      0.52      0.67       411\n","\n","    accuracy                           0.75       812\n","   macro avg       0.82      0.75      0.73       812\n","weighted avg       0.82      0.75      0.73       812\n","\n","*********************************\n","26/26 [==============================] - 1s 37ms/step - loss: 0.8138 - accuracy: 0.8805\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 88.054186 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.57      1.00      0.73       401\n","           1       0.99      0.27      0.43       411\n","\n","    accuracy                           0.63       812\n","   macro avg       0.78      0.64      0.58       812\n","weighted avg       0.78      0.63      0.58       812\n","\n","*********************************\n","26/26 [==============================] - 1s 36ms/step - loss: 0.9041 - accuracy: 0.8842\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 88.423645 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.99      0.77       401\n","           1       0.97      0.44      0.60       411\n","\n","    accuracy                           0.71       812\n","   macro avg       0.80      0.71      0.69       812\n","weighted avg       0.80      0.71      0.69       812\n","\n","*********************************\n","26/26 [==============================] - 2s 65ms/step - loss: 0.8549 - accuracy: 0.8842\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 88.423645 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.99      0.75       401\n","           1       0.98      0.35      0.52       411\n","\n","    accuracy                           0.67       812\n","   macro avg       0.79      0.67      0.63       812\n","weighted avg       0.79      0.67      0.63       812\n","\n","*********************************\n","26/26 [==============================] - 2s 67ms/step - loss: 0.9746 - accuracy: 0.8830\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 88.300490 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.98      0.80       401\n","           1       0.96      0.54      0.69       411\n","\n","    accuracy                           0.76       812\n","   macro avg       0.82      0.76      0.75       812\n","weighted avg       0.82      0.76      0.75       812\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["#####Pretrained Embedding"],"metadata":{"id":"JerAC4wQ_CSZ"}},{"cell_type":"code","source":["#create embedding layer\n","pretrained_binary_embedding_layer = Embedding(len(binary_tokenizer.word_index)+1,  EMBEDDING_DIM ,weights = [pretrained_embedding_matrix_binary],input_length = binary_max_length)\n","pretrained_binary_acc = []\n","pretrained_binary_f1 = []\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","      model = Sequential()\n","      model.add(pretrained_binary_embedding_layer)\n","      model.add(Conv1D(filters=f, kernel_size=k, activation='relu'))\n","      model.add(MaxPooling1D(pool_size=2))\n","      model.add(Flatten())\n","      model.add(Dense(h, activation='relu'))\n","      model.add(Dense(1, activation='sigmoid')) #using sigmoid because of binary classficiation\n","\n","      # compile network\n","      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model.fit(x_binary_train_pad, y_binary_train, epochs=8,verbose= 0,  validation_data=(x_binary_validation_pad, y_binary_validation))\n","\n","      loss, acc = model.evaluate(x_binary_test_pad, y_binary_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model.predict(x_binary_test_pad)\n","      predicted_classes = y_pred.astype(int).tolist()\n","      print(classification_report(y_binary_test, predicted_classes))\n","      print(\"*********************************\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CmDj7113_Fl1","outputId":"372df6ec-28b7-4df9-e7d4-314f4e481d6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26/26 [==============================] - 1s 23ms/step - loss: 0.5756 - accuracy: 0.8990\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 89.901477 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.57      1.00      0.73       401\n","           1       0.99      0.28      0.44       411\n","\n","    accuracy                           0.63       812\n","   macro avg       0.78      0.64      0.58       812\n","weighted avg       0.79      0.63      0.58       812\n","\n","*********************************\n","26/26 [==============================] - 1s 23ms/step - loss: 0.7505 - accuracy: 0.8830\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 88.300490 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.99      0.77       401\n","           1       0.98      0.43      0.60       411\n","\n","    accuracy                           0.71       812\n","   macro avg       0.81      0.71      0.69       812\n","weighted avg       0.81      0.71      0.69       812\n","\n","*********************************\n","26/26 [==============================] - 1s 39ms/step - loss: 0.7744 - accuracy: 0.8805\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 88.054186 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.99      0.78       401\n","           1       0.98      0.48      0.64       411\n","\n","    accuracy                           0.73       812\n","   macro avg       0.81      0.73      0.71       812\n","weighted avg       0.81      0.73      0.71       812\n","\n","*********************************\n","26/26 [==============================] - 1s 37ms/step - loss: 0.8151 - accuracy: 0.8781\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 87.807882 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.99      0.74       401\n","           1       0.98      0.32      0.48       411\n","\n","    accuracy                           0.65       812\n","   macro avg       0.78      0.66      0.61       812\n","weighted avg       0.78      0.65      0.61       812\n","\n","*********************************\n","26/26 [==============================] - 1s 37ms/step - loss: 0.7429 - accuracy: 0.8867\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 88.669950 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.54      1.00      0.70       401\n","           1       0.99      0.18      0.30       411\n","\n","    accuracy                           0.58       812\n","   macro avg       0.76      0.59      0.50       812\n","weighted avg       0.77      0.58      0.50       812\n","\n","*********************************\n","26/26 [==============================] - 1s 36ms/step - loss: 0.9519 - accuracy: 0.8818\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 88.177341 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.99      0.76       401\n","           1       0.98      0.42      0.58       411\n","\n","    accuracy                           0.70       812\n","   macro avg       0.80      0.70      0.67       812\n","weighted avg       0.80      0.70      0.67       812\n","\n","*********************************\n","26/26 [==============================] - 2s 64ms/step - loss: 0.9173 - accuracy: 0.8768\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 87.684727 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.99      0.79       401\n","           1       0.98      0.49      0.65       411\n","\n","    accuracy                           0.73       812\n","   macro avg       0.81      0.74      0.72       812\n","weighted avg       0.82      0.73      0.72       812\n","\n","*********************************\n","26/26 [==============================] - 2s 70ms/step - loss: 1.0569 - accuracy: 0.8756\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 87.561578 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.99      0.79       401\n","           1       0.97      0.51      0.67       411\n","\n","    accuracy                           0.74       812\n","   macro avg       0.82      0.75      0.73       812\n","weighted avg       0.82      0.74      0.73       812\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["####Neural Models for Multiclass Classification\n"],"metadata":{"id":"lem7NneJffL-"}},{"cell_type":"markdown","source":["#####Randomly Initialized Word Embeddings"],"metadata":{"id":"fXHyl0PIfsL9"}},{"cell_type":"code","source":["# Create Embedding Matrices and Layers\n","EMBEDDING_DIM = 100\n","\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","      model_random_multi = Sequential()\n","      model_random_multi.add(Embedding(multi_vocab_size, EMBEDDING_DIM, input_length = multi_max_length))\n","      model_random_multi.add(Conv1D(filters=f, kernel_size=k, activation='relu'))\n","      model_random_multi.add(MaxPooling1D(pool_size=2))\n","      model_random_multi.add(Flatten())\n","      model_random_multi.add(Dense(h, activation='relu'))\n","      model_random_multi.add(Dense(5, activation='softmax'))\n","      # compile network\n","      model_random_multi.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model_random_multi.fit(x_multi_train_pad, y_multi_train, epochs=8, verbose=0, validation_data=(x_multi_validation_pad, y_multi_validation))\n","      loss, acc = model_random_multi.evaluate(x_multi_test_pad, y_multi_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model_random_multi.predict(x_multi_test_pad)\n","      predicted_classes =  np.argmax(y_pred, axis=1)\n","      print(classification_report(y_multi_test, predicted_classes))\n","      print(\"*********************************\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLheLUUGfxMq","outputId":"64a24314-d723-49eb-fcc6-77b5909ce6cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 1s 22ms/step - loss: 3.4149 - accuracy: 0.4460\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 44.600001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.54      0.58       192\n","           1       0.39      0.43      0.41       180\n","           2       0.35      0.42      0.38       219\n","           3       0.32      0.35      0.34       184\n","           4       0.64      0.49      0.55       225\n","\n","    accuracy                           0.45      1000\n","   macro avg       0.46      0.44      0.45      1000\n","weighted avg       0.47      0.45      0.45      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 23ms/step - loss: 4.0644 - accuracy: 0.4570\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 45.699999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.48      0.59       192\n","           1       0.36      0.46      0.40       180\n","           2       0.36      0.41      0.38       219\n","           3       0.35      0.46      0.40       184\n","           4       0.69      0.48      0.56       225\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.50      0.46      0.47      1000\n","weighted avg       0.51      0.46      0.47      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 38ms/step - loss: 3.4036 - accuracy: 0.4890\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 48.899999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.51      0.59       192\n","           1       0.37      0.57      0.45       180\n","           2       0.47      0.38      0.42       219\n","           3       0.38      0.36      0.37       184\n","           4       0.60      0.62      0.61       225\n","\n","    accuracy                           0.49      1000\n","   macro avg       0.51      0.49      0.49      1000\n","weighted avg       0.51      0.49      0.49      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 39ms/step - loss: 4.0115 - accuracy: 0.4820\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 48.199999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.51      0.60       192\n","           1       0.37      0.51      0.43       180\n","           2       0.42      0.40      0.41       219\n","           3       0.35      0.46      0.39       184\n","           4       0.71      0.54      0.62       225\n","\n","    accuracy                           0.48      1000\n","   macro avg       0.52      0.48      0.49      1000\n","weighted avg       0.52      0.48      0.49      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 38ms/step - loss: 4.2259 - accuracy: 0.4670\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 46.700001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.62      0.63       192\n","           1       0.29      0.47      0.36       180\n","           2       0.47      0.30      0.37       219\n","           3       0.37      0.41      0.39       184\n","           4       0.70      0.54      0.61       225\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.49      0.47      0.47      1000\n","weighted avg       0.50      0.47      0.47      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 39ms/step - loss: 3.6013 - accuracy: 0.4650\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 46.500000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.54      0.61       192\n","           1       0.36      0.49      0.42       180\n","           2       0.40      0.40      0.40       219\n","           3       0.32      0.39      0.35       184\n","           4       0.68      0.52      0.59       225\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.49      0.46      0.47      1000\n","weighted avg       0.50      0.47      0.48      1000\n","\n","*********************************\n","32/32 [==============================] - 2s 67ms/step - loss: 4.1376 - accuracy: 0.4700\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 47.000000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.57      0.58       192\n","           1       0.42      0.37      0.40       180\n","           2       0.44      0.44      0.44       219\n","           3       0.33      0.52      0.41       184\n","           4       0.68      0.45      0.54       225\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.49      0.47      0.47      1000\n","weighted avg       0.50      0.47      0.48      1000\n","\n","*********************************\n","32/32 [==============================] - 2s 65ms/step - loss: 4.1577 - accuracy: 0.4780\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 47.799999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.53      0.60       192\n","           1       0.41      0.54      0.47       180\n","           2       0.41      0.40      0.41       219\n","           3       0.35      0.48      0.40       184\n","           4       0.69      0.46      0.55       225\n","\n","    accuracy                           0.48      1000\n","   macro avg       0.51      0.48      0.49      1000\n","weighted avg       0.52      0.48      0.49      1000\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["#####Word2Vec Embedding"],"metadata":{"id":"TiTc_m4k0ilV"}},{"cell_type":"code","source":["w2v_multi_embedding_layer = Embedding(len(multi_tokenizer.word_index)+1,  EMBEDDING_DIM ,weights = [multi_w2c_embedding_matrix],input_length = multi_max_length)\n","\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","\n","      model_w2v_multi = Sequential()\n","      model_w2v_multi.add(w2v_multi_embedding_layer)\n","      model_w2v_multi.add(Conv1D(filters=f, kernel_size=k, activation='relu'))\n","      model_w2v_multi.add(MaxPooling1D(pool_size=2))\n","      model_w2v_multi.add(Flatten())\n","      model_w2v_multi.add(Dense(h, activation='relu'))\n","      model_w2v_multi.add(Dense(5, activation='softmax'))\n","\n","      # compile network\n","      model_w2v_multi.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model_w2v_multi.fit(x_multi_train_pad, y_multi_train, epochs=8, verbose=0, validation_data=(x_multi_validation_pad, y_multi_validation))\n","\n","      loss, acc = model_w2v_multi.evaluate(x_multi_test_pad, y_multi_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model_w2v_multi.predict(x_multi_test_pad)\n","      predicted_classes =  np.argmax(y_pred, axis=1)\n","      print(classification_report(y_multi_test, predicted_classes))\n","      print(\"*********************************\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZWtBZBH0oTN","outputId":"422415b7-749c-4cdb-d6d7-5e48e5ea84c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 1s 24ms/step - loss: 2.4421 - accuracy: 0.4860\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 48.600000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.62      0.63       192\n","           1       0.38      0.44      0.41       180\n","           2       0.38      0.39      0.38       219\n","           3       0.40      0.50      0.44       184\n","           4       0.75      0.49      0.59       225\n","\n","    accuracy                           0.49      1000\n","   macro avg       0.51      0.49      0.49      1000\n","weighted avg       0.52      0.49      0.49      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 25ms/step - loss: 4.8432 - accuracy: 0.4770\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 47.700000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.61      0.64       192\n","           1       0.35      0.47      0.40       180\n","           2       0.40      0.33      0.36       219\n","           3       0.36      0.46      0.40       184\n","           4       0.72      0.52      0.60       225\n","\n","    accuracy                           0.48      1000\n","   macro avg       0.50      0.48      0.48      1000\n","weighted avg       0.51      0.48      0.48      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 40ms/step - loss: 5.0593 - accuracy: 0.4480\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 44.800001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.57      0.59       192\n","           1       0.36      0.29      0.32       180\n","           2       0.34      0.47      0.40       219\n","           3       0.35      0.40      0.37       184\n","           4       0.65      0.49      0.56       225\n","\n","    accuracy                           0.45      1000\n","   macro avg       0.46      0.44      0.45      1000\n","weighted avg       0.47      0.45      0.45      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 40ms/step - loss: 5.9264 - accuracy: 0.4530\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 45.300001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.51      0.61       192\n","           1       0.37      0.46      0.41       180\n","           2       0.35      0.36      0.35       219\n","           3       0.33      0.47      0.39       184\n","           4       0.69      0.48      0.57       225\n","\n","    accuracy                           0.45      1000\n","   macro avg       0.50      0.45      0.46      1000\n","weighted avg       0.50      0.45      0.47      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 38ms/step - loss: 1.6098 - accuracy: 0.2250\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 22.499999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       192\n","           1       0.00      0.00      0.00       180\n","           2       0.00      0.00      0.00       219\n","           3       0.00      0.00      0.00       184\n","           4       0.23      1.00      0.37       225\n","\n","    accuracy                           0.23      1000\n","   macro avg       0.04      0.20      0.07      1000\n","weighted avg       0.05      0.23      0.08      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 37ms/step - loss: 7.0859 - accuracy: 0.4400\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 44.000000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.51      0.59       192\n","           1       0.33      0.39      0.36       180\n","           2       0.37      0.38      0.38       219\n","           3       0.34      0.52      0.41       184\n","           4       0.68      0.41      0.51       225\n","\n","    accuracy                           0.44      1000\n","   macro avg       0.48      0.44      0.45      1000\n","weighted avg       0.49      0.44      0.45      1000\n","\n","*********************************\n","32/32 [==============================] - 2s 65ms/step - loss: 7.2361 - accuracy: 0.4380\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 43.799999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.47      0.57       192\n","           1       0.35      0.39      0.37       180\n","           2       0.34      0.35      0.35       219\n","           3       0.32      0.51      0.40       184\n","           4       0.67      0.47      0.55       225\n","\n","    accuracy                           0.44      1000\n","   macro avg       0.48      0.44      0.45      1000\n","weighted avg       0.49      0.44      0.45      1000\n","\n","*********************************\n","32/32 [==============================] - 2s 67ms/step - loss: 9.3164 - accuracy: 0.4630\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 46.300000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.62      0.64       192\n","           1       0.37      0.44      0.41       180\n","           2       0.36      0.36      0.36       219\n","           3       0.35      0.46      0.40       184\n","           4       0.69      0.44      0.54       225\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.49      0.47      0.47      1000\n","weighted avg       0.49      0.46      0.47      1000\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["#####Pretrained Embeddings"],"metadata":{"id":"9EMzxVR67M0a"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","\n","#create embedding layer\n","pretrained_multi_embedding_layer = Embedding(len(multi_tokenizer.word_index)+1,  EMBEDDING_DIM ,weights = [pretrained_embedding_matrix_multi],input_length = multi_max_length)\n","\n","filters = [32,64]\n","kernels = [8,16]\n","hidden_layers_size = [10,32]\n","\n","for f in filters:\n","  for k in kernels:\n","    for h in hidden_layers_size:\n","      model_pretrained_multi = Sequential()\n","      model_pretrained_multi.add(pretrained_multi_embedding_layer)\n","      model_pretrained_multi.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n","      model_pretrained_multi.add(MaxPooling1D(pool_size=2))\n","      model_pretrained_multi.add(Flatten())\n","      model_pretrained_multi.add(Dense(32, activation='relu'))\n","      model_pretrained_multi.add(Dense(5, activation='softmax'))\n","\n","      # compile network\n","      model_pretrained_multi.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","      # fit network\n","      model_pretrained_multi.fit(x_multi_train_pad, y_multi_train, epochs=8, verbose=0, validation_data=(x_multi_validation_pad, y_multi_validation))\n","      \n","      loss, acc = model_pretrained_multi.evaluate(x_multi_test_pad, y_multi_test)\n","      print(\"************ FILTER SIZE: \" ,f, \"KERNEL: \", k , \"HIDDEN LAYER: \", h ,'TEST ACCURACY: %f' % (acc*100) , \"************\")\n","      print(\"************ CLASSIFICATION REPORT ************\")\n","      y_pred = model_pretrained_multi.predict(x_multi_test_pad)\n","      predicted_classes =  np.argmax(y_pred, axis=1)\n","      print(classification_report(y_multi_test, predicted_classes))\n","      print(\"*********************************\")\n","\n","      #confusion matrix\n","      #cf_matrix = confusion_matrix(y_multi_test, y_pred_class)\n","      #disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix)\n","      #disp.plot()\n","      #plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yyaL0HB7QrO","outputId":"785ee3fe-ec28-401a-d5fa-72ce8f79dd67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 1s 23ms/step - loss: 2.8835 - accuracy: 0.4560\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 45.600000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.62      0.61       192\n","           1       0.36      0.39      0.37       180\n","           2       0.35      0.33      0.34       219\n","           3       0.32      0.36      0.34       184\n","           4       0.66      0.57      0.61       225\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.46      0.45      0.46      1000\n","weighted avg       0.47      0.46      0.46      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 23ms/step - loss: 4.4469 - accuracy: 0.4720\n","************ FILTER SIZE:  32 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 47.200000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.64      0.64       192\n","           1       0.37      0.45      0.41       180\n","           2       0.35      0.32      0.33       219\n","           3       0.37      0.47      0.41       184\n","           4       0.72      0.49      0.58       225\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.49      0.48      0.48      1000\n","weighted avg       0.50      0.47      0.48      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 24ms/step - loss: 5.1194 - accuracy: 0.4540\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 45.400000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.52      0.59       192\n","           1       0.34      0.45      0.39       180\n","           2       0.37      0.38      0.38       219\n","           3       0.35      0.46      0.40       184\n","           4       0.70      0.47      0.56       225\n","\n","    accuracy                           0.45      1000\n","   macro avg       0.49      0.46      0.46      1000\n","weighted avg       0.49      0.45      0.46      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 23ms/step - loss: 5.8638 - accuracy: 0.4510\n","************ FILTER SIZE:  32 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 45.100001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.53      0.60       192\n","           1       0.33      0.47      0.39       180\n","           2       0.37      0.34      0.35       219\n","           3       0.35      0.47      0.40       184\n","           4       0.72      0.46      0.56       225\n","\n","    accuracy                           0.45      1000\n","   macro avg       0.49      0.45      0.46      1000\n","weighted avg       0.50      0.45      0.46      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 22ms/step - loss: 6.9992 - accuracy: 0.4650\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  10 TEST ACCURACY: 46.500000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.58      0.61       192\n","           1       0.37      0.45      0.40       180\n","           2       0.39      0.38      0.39       219\n","           3       0.36      0.46      0.40       184\n","           4       0.68      0.46      0.55       225\n","\n","    accuracy                           0.47      1000\n","   macro avg       0.49      0.47      0.47      1000\n","weighted avg       0.49      0.47      0.47      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 22ms/step - loss: 8.1459 - accuracy: 0.4390\n","************ FILTER SIZE:  64 KERNEL:  8 HIDDEN LAYER:  32 TEST ACCURACY: 43.900001 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.48      0.58       192\n","           1       0.35      0.56      0.43       180\n","           2       0.38      0.35      0.37       219\n","           3       0.34      0.53      0.41       184\n","           4       0.76      0.32      0.45       225\n","\n","    accuracy                           0.44      1000\n","   macro avg       0.51      0.45      0.45      1000\n","weighted avg       0.52      0.44      0.45      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 23ms/step - loss: 8.1654 - accuracy: 0.4640\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  10 TEST ACCURACY: 46.399999 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.60      0.64       192\n","           1       0.38      0.47      0.42       180\n","           2       0.38      0.38      0.38       219\n","           3       0.35      0.46      0.40       184\n","           4       0.68      0.43      0.52       225\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.49      0.47      0.47      1000\n","weighted avg       0.50      0.46      0.47      1000\n","\n","*********************************\n","32/32 [==============================] - 1s 23ms/step - loss: 7.8929 - accuracy: 0.4630\n","************ FILTER SIZE:  64 KERNEL:  16 HIDDEN LAYER:  32 TEST ACCURACY: 46.300000 ************\n","************ CLASSIFICATION REPORT ************\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.64      0.64       192\n","           1       0.36      0.42      0.39       180\n","           2       0.35      0.32      0.33       219\n","           3       0.35      0.48      0.40       184\n","           4       0.70      0.48      0.57       225\n","\n","    accuracy                           0.46      1000\n","   macro avg       0.48      0.47      0.47      1000\n","weighted avg       0.49      0.46      0.47      1000\n","\n","*********************************\n"]}]},{"cell_type":"markdown","source":["## My Report\n","###Data\n","After reaing the train and test data, I have checked the first 3 instances of the train dataset. I have seen that there are 3 fields; Unnamed, text and label. I have checked if any of instances of the train data contains NaN values in these fields. There doese not exist any NaN values so it won't need any handling.\n","###Preprocessing\n","In the preprocessing, I lowercased all the letters, removed html tags, URLs, stopwords, extra unnecesary whitespaces to reduce the number of features. I have chosed not to use Porter Stemmer because as we have seen in the lecture, it stems the words too much and it has low performance.\n","###Naive Bayes\n","In Naive Bayes, I have created the pipeline with TfIdfVectorizer,  DenseTramsformer and Gaussian NB.\n","For binary classification, I found the best result by using min_df = 100 and ngram_range = (1,2) for TfIdfVectorizer with F1 Score:  0.853960396039604 and\n","Accuracy Score:  0.854679802955665. Min_df=100 was expected because our corpus isn't very large and since these are reviews from users, there should exist unique slang words as well. \n","\n","For multiclass classification, I have tried the model with different norms as well as ngram ranges and min_df. Best result came with l2 norm, ngram_range = (1,2) and min_df=100 with F1 Score:  0.46108191335759807\n","Accuracy Score:  0.475. \n","\n","Interesting outcome is that trigrams did not perform well on the model and I have created the pipeline using n_gram range as (1,2) for both of the classifications.\n","Overall, Naive Bayes did not perform well due to its conditional independence assumption for the features\n","\n","Accuracy and f1 score reduces drastically for multiclass classification and Naive Bayes is not a good fit for the multiclass classification problem.\n","###Logistic Regression\n","In Logistic Regression, I have created the pipeline with TdIdfVectorizer and Logistic Regression Classifier.\n","\n","For binary classification, I found the best result by using min_df = 100, n_gram_range = (1,2) and l1_penalty = 0 => meaning penalty= l2 with F1 Score:  0.8899876390605687\n","Accuracy Score:  0.8903940886699507 which is a better performance than binary classification with naive bayes.\n","\n","For multiclass classification, I have found the best result by using min_df =100, n_gram range = (1,2) for TfIdfVectorizer and penalty = l2 for Logistic Regression Classifier. Got the scores as F1 Score:  0.5195094567239478\n","Accuracy Score:  0.523 which is again a better performance than Naive Bayes.\n","###CNN\n","First, I had to prepare the data for CNN. For that purpose i applied tokenization and padding so that each word will have the same length.\n","\n","From the lectures, we know that simple models work better for NLP classification tasks. So, i used 1 convolution layer, max pooling and then 2 dense layers. I have tried kernel sizes as 8 and 16, amount of filters as 16 and 32 and hidden layer size as 10 and 32. \n","For the last dense layer, sizes vary as 1 and 5. 1 for binary classification and 5 for multiclass.\n","\n","I have used word embedding dimensions as 100\n","\n","For binary classification:\n","\n","Randomly Initialized Embeddings performed better with 32 filters, kernel size as 16 and hidden layer size as 32 with test accuracy: 89.901477\n","\n","Word2Vec Embeddings performed better with 32 filters kernel size as 16 and hidden layer size as 32 with test accuracy: 89.162564 and highest f1 scores. \n","\n","Pretrained Embeddings performed better with 32 filters kernel size as 8 and hidden layer size as  10 with highest test accuracy: 89.901477.\n","\n","Overall, it is seen that small filter size performs well for these models.\n","\n","For multiclass:\n","\n","Randomly Initialized Embeddings performed better with 32 filters, kernel size as 16 and hidden layer size as 10 with test accuracy: 48.899999\n","\n","\n","Word2Vec Embeddings performed better with 32 filters, kernel size as 8  and hidden layer size as 10 with test accuracy: 48.600000\n","\n","Pretrained Embeddings performed better with 32 filters, kernel size as 8 and hidden layer size as 32 with test accuracy: 47.200000\n","\n","Conclusion:\n","For binary classification, CNN with randomly initialized embedding and CNN with pretrained embedding (both has accuracy score 89.901477) performed the best. Overall, CNN for binary classification performed better with higher kernel size and higher hidden layer size, 16 and 32 respectively.\n","However for multiclass classification, CNN with randomly initialized embedding performed the best.\n","For multiclass, CNN performed better with smaller kernel size and hidden layer size, 8 and 10 respectively.\n","\n","For both binary and multiclass classification, CNN performed similar to NB and Logistic Regression. This was saddening. CNN outperformed NB and LR in binary classification but fell low on multiclass classification.\n"],"metadata":{"id":"oCT-Zt3ZMocG"}}]}